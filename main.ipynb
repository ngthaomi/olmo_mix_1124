{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c758cf4",
   "metadata": {},
   "source": [
    "# **Brand Sentiment Analysis using OLMo 2 Pre-training Dataset** (OLMo Mix 1124)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdfc934-f454-4547-822e-c400c561776f",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "- [0. Setup](#0-setup)  \n",
    "- [1. Data Loading](#1-data-loading)  \n",
    "- [2. Data Exploration](#2-data-exploration)  \n",
    "- [3. Data Preprocessing](#3-data-preprocessing)  \n",
    "    - [3.1 Data Cleaning](#31-data-cleaning)   \n",
    "    - [3.2 Feature Engineering](#32-feature-engineering)  \n",
    "- [4. Brand Sentiment Analysis](#4-brand-sentiment-analysis)  \n",
    "    - [4.1 Lexicon-Based](#41-lexicon-based)  \n",
    "    - [4.2 Transformer-based](#42-transformer-based)\n",
    "- [5. Brand-Specific Analysis](#5-brand-specific-analysis)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fcf565-b4d6-4ee3-b89d-c84c6eae06ef",
   "metadata": {},
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a1cc666-f0ae-4f98-aac7-efaf3d8536bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas>=2.2.3 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: numpy>=2.0.2 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (2.0.2)\n",
      "Requirement already satisfied: pyspark>=3.5.0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (3.5.0)\n",
      "Requirement already satisfied: nltk>=3.8 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (3.8.1)\n",
      "Collecting emoji>=2.14.1 (from -r requirements.txt (line 5))\n",
      "  Using cached emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting transformers>=4.52.4 (from -r requirements.txt (line 6))\n",
      "  Using cached transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting torch>=2.7.0 (from -r requirements.txt (line 7))\n",
      "  Using cached torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Collecting torchvision (from -r requirements.txt (line 8))\n",
      "  Using cached torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio (from -r requirements.txt (line 9))\n",
      "  Using cached torchaudio-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (3.10.0)\n",
      "Collecting datasets (from -r requirements.txt (line 11))\n",
      "  Using cached datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (19.0.0)\n",
      "Collecting fastparquet (from -r requirements.txt (line 13))\n",
      "  Using cached fastparquet-2024.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 14)) (6.29.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas>=2.2.3->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas>=2.2.3->-r requirements.txt (line 1)) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas>=2.2.3->-r requirements.txt (line 1)) (2025.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.12/site-packages (from pyspark>=3.5.0->-r requirements.txt (line 3)) (0.10.9.7)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.12/site-packages (from nltk>=3.8->-r requirements.txt (line 4)) (8.1.8)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.12/site-packages (from nltk>=3.8->-r requirements.txt (line 4)) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.12/site-packages (from nltk>=3.8->-r requirements.txt (line 4)) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from nltk>=3.8->-r requirements.txt (line 4)) (4.67.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers>=4.52.4->-r requirements.txt (line 6)) (3.17.0)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers>=4.52.4->-r requirements.txt (line 6))\n",
      "  Using cached huggingface_hub-0.32.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers>=4.52.4->-r requirements.txt (line 6)) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers>=4.52.4->-r requirements.txt (line 6)) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers>=4.52.4->-r requirements.txt (line 6)) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers>=4.52.4->-r requirements.txt (line 6))\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers>=4.52.4->-r requirements.txt (line 6))\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.12/site-packages (from torch>=2.7.0->-r requirements.txt (line 7)) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=2.7.0->-r requirements.txt (line 7)) (75.8.0)\n",
      "Collecting sympy>=1.13.3 (from torch>=2.7.0->-r requirements.txt (line 7))\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=2.7.0->-r requirements.txt (line 7)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=2.7.0->-r requirements.txt (line 7)) (3.1.5)\n",
      "Collecting fsspec (from torch>=2.7.0->-r requirements.txt (line 7))\n",
      "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=2.7.0->-r requirements.txt (line 7))\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=2.7.0->-r requirements.txt (line 7))\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=2.7.0->-r requirements.txt (line 7))\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=2.7.0->-r requirements.txt (line 7))\n",
      "  Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch>=2.7.0->-r requirements.txt (line 7))\n",
      "  Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch>=2.7.0->-r requirements.txt (line 7))\n",
      "  Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch>=2.7.0->-r requirements.txt (line 7))\n",
      "  Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=2.7.0->-r requirements.txt (line 7))\n",
      "  Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch>=2.7.0->-r requirements.txt (line 7))\n",
      "  Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch>=2.7.0->-r requirements.txt (line 7))\n",
      "  Using cached nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch>=2.7.0->-r requirements.txt (line 7))\n",
      "  Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch>=2.7.0->-r requirements.txt (line 7))\n",
      "  Using cached nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch>=2.7.0->-r requirements.txt (line 7))\n",
      "  Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch>=2.7.0->-r requirements.txt (line 7))\n",
      "  Using cached nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.1 (from torch>=2.7.0->-r requirements.txt (line 7))\n",
      "  Using cached triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.12/site-packages (from torchvision->-r requirements.txt (line 8)) (11.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 10)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 10)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 10)) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 10)) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 10)) (3.2.1)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->-r requirements.txt (line 11))\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from datasets->-r requirements.txt (line 11))\n",
      "  Using cached xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets->-r requirements.txt (line 11))\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec (from torch>=2.7.0->-r requirements.txt (line 7))\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting cramjam>=2.3 (from fastparquet->-r requirements.txt (line 13))\n",
      "  Using cached cramjam-2.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 14)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 14)) (1.8.12)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/conda/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 14)) (8.32.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 14)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 14)) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 14)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 14)) (1.6.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 14)) (6.1.1)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/conda/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 14)) (26.2.1)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 14)) (6.4.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /opt/conda/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 14)) (5.14.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 11)) (3.11.12)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub<1.0,>=0.30.0->transformers>=4.52.4->-r requirements.txt (line 6))\n",
      "  Using cached hf_xet-1.1.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 14)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 14)) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 14)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 14)) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 14)) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /opt/conda/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 14)) (0.6.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 14)) (4.3.6)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=2.2.3->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers>=4.52.4->-r requirements.txt (line 6)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers>=4.52.4->-r requirements.txt (line 6)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers>=4.52.4->-r requirements.txt (line 6)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers>=4.52.4->-r requirements.txt (line 6)) (2024.12.14)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.7.0->-r requirements.txt (line 7))\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=2.7.0->-r requirements.txt (line 7)) (3.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 11)) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 11)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 11)) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 11)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 11)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 11)) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 11)) (1.18.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/conda/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 14)) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->-r requirements.txt (line 14)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->-r requirements.txt (line 14)) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 14)) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 14)) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 14)) (0.2.3)\n",
      "Using cached emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "Using cached transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "Using cached torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl (821.0 MB)\n",
      "Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "Using cached nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "Using cached nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Using cached triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
      "Using cached torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl (7.5 MB)\n",
      "Using cached torchaudio-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl (3.5 MB)\n",
      "Using cached datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Using cached fastparquet-2024.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "Using cached cramjam-2.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Using cached huggingface_hub-0.32.4-py3-none-any.whl (512 kB)\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Using cached xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Using cached hf_xet-1.1.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: nvidia-cusparselt-cu12, mpmath, xxhash, triton, sympy, safetensors, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, hf-xet, fsspec, emoji, dill, cramjam, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, multiprocess, huggingface-hub, tokenizers, nvidia-cusolver-cu12, fastparquet, transformers, torch, datasets, torchvision, torchaudio\n",
      "Successfully installed cramjam-2.10.0 datasets-3.6.0 dill-0.3.8 emoji-2.14.1 fastparquet-2024.11.0 fsspec-2025.3.0 hf-xet-1.1.3 huggingface-hub-0.32.4 mpmath-1.3.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 safetensors-0.5.3 sympy-1.14.0 tokenizers-0.21.1 torch-2.7.1 torchaudio-2.7.1 torchvision-0.22.1 transformers-4.52.4 triton-3.3.1 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "319f76d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b13a1817-50a8-4971-ba8b-aa21a5dd4883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf, pandas_udf, PandasUDFType, arrays_zip, array_contains, substring, length, explode, first, avg, when, monotonically_increasing_id\n",
    "from pyspark.sql.functions import to_date, dayofmonth, month, year\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType, FloatType, BooleanType, ArrayType, StructType, StructField\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from collections import defaultdict\n",
    "from emoji import demojize\n",
    "from urllib.parse import urlparse\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324cefc4-be05-4082-81ae-80cbd6ec1f6c",
   "metadata": {},
   "source": [
    "# 1. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feea5af6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/06 11:32:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Spark initialisation\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Olmo Mix 1124 Sentiment Analysis\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"16g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"4\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bf39ec6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+-------------------------------+--------------------+-------------------+--------------------+--------------------+--------------------+---------------------------------------------------------------+\n",
      "|bff_contained_ngram_count_before_dedupe|language_id_whole_page_fasttext|            metadata|previous_word_count|                text|                 url|            warcinfo|fasttext_openhermes_reddit_eli5_vs_rw_v2_bigram_200k_train_prob|\n",
      "+---------------------------------------+-------------------------------+--------------------+-------------------+--------------------+--------------------+--------------------+---------------------------------------------------------------+\n",
      "|                                      1|           {0.9661467671394348}|{27167, applicati...|                917|Take action now: ...|http://24ahead.co...|robots: classic\\r...|                                            0.06953519582748413|\n",
      "|                                     69|           {0.9487149715423584}|{102017, applicat...|                 95|IUCN has been inv...|http://Lorena.agu...|robots: classic\\r...|                                             0.3574485778808594|\n",
      "|                                      7|           {0.8384741544723511}|{2709, applicatio...|                226|AAS 203rd Meeting...|http://aas.org/ar...|robots: classic\\r...|                                           0.027546942234039307|\n",
      "|                                     31|           {0.9725183248519896}|{42807, applicati...|                909|Farris: Clampetts...|http://amarillo.c...|robots: classic\\r...|                                             0.0258486270904541|\n",
      "|                                     29|           {0.8794317841529846}|{80041, applicati...|                471|Take the 2-minute...|http://android.st...|robots: classic\\r...|                                             0.1457725167274475|\n",
      "|                                      0|           {0.9637343883514404}|{58953, applicati...|                179|Are the Phoenix a...|http://androidfor...|robots: classic\\r...|                                            0.10406094789505005|\n",
      "|                                      4|           {0.6833912134170532}|{46225, applicati...|                129|When engaging in ...|http://ar.urbandi...|robots: classic\\r...|                                             0.4722307324409485|\n",
      "|                                      0|           {0.9390441179275512}|{48406, applicati...|                828|Scientific Method...|http://arstechnic...|robots: classic\\r...|                                            0.16863960027694702|\n",
      "|                                     20|           {0.9516177773475648}|{46857, applicati...|                597|What piracy crisi...|http://arstechnic...|robots: classic\\r...|                                             0.0899609923362732|\n",
      "|                                     46|           {0.8379496932029724}|{69093, applicati...|                198|Take the 2-minute...|http://askubuntu....|robots: classic\\r...|                                           0.042100727558135986|\n",
      "|                                     33|           {0.9529104232788086}|{82485, applicati...|                890|Take the 2-minute...|http://bicycles.s...|robots: classic\\r...|                                               0.64274001121521|\n",
      "|                                      5|            {0.974293291568756}|{12304, applicati...|                261|vishn010: January...|http://blog.lib.u...|robots: classic\\r...|                                           0.027925968170166016|\n",
      "|                                     46|           {0.9686204195022584}|{136635, applicat...|               4155|Friday, July 25, ...|http://blog.posit...|robots: classic\\r...|                                           0.022680580615997314|\n",
      "|                                      7|            {0.972939908504486}|{63567, applicati...|                356|\\n\\nRetro Thursda...|http://blog.times...|robots: classic\\r...|                                            0.04710876941680908|\n",
      "|                                     11|           {0.8922050595283508}|{4632, applicatio...|                108|The Motley Fool D...|http://boards.foo...|robots: classic\\r...|                                             0.5219071507453918|\n",
      "|                                      0|           {0.9776951670646667}|{104365, applicat...|               1083|HOME > Chowhound ...|http://chowhound....|robots: classic\\r...|                                            0.21541708707809448|\n",
      "|                                      0|            {0.983411192893982}|{92371, applicati...|                533|HOME > Chowhound ...|http://chowhound....|robots: classic\\r...|                                            0.03039240837097168|\n",
      "|                                      0|           {0.9485079646110536}|{95913, applicati...|                309|HOME > Chowhound ...|http://chowhound....|robots: classic\\r...|                                            0.19296503067016602|\n",
      "|                                      9|            {0.956630527973175}|{136654, applicat...|               1101|HOME > Chowhound ...|http://chowhound....|robots: classic\\r...|                                             0.6440867185592651|\n",
      "|                                      0|           {0.9562400579452516}|{132646, applicat...|               1090|HOME > Chowhound ...|http://chowhound....|robots: classic\\r...|                                            0.07875239849090576|\n",
      "+---------------------------------------+-------------------------------+--------------------+-------------------+--------------------+--------------------+--------------------+---------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load pretraining dataset\n",
    "df = spark.read.parquet(\"data/olmomix1124_01.parquet\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521c4bff-f6fe-40b6-a372-7d12fadbd8aa",
   "metadata": {},
   "source": [
    "| Column Name | Description |\n",
    "|-------------|-------------|\n",
    "| `bff_contained_ngram_count_before_dedupe` | Number of known n-grams from the BFF (Base Filtered Fragments) list that were found before deduplication. Higher counts imply overlap with previously seen content, used in deduplication. |\n",
    "| `language_id_whole_page_fasttext` | Probability or confidence that the whole page is in English. |\n",
    "| `metadata` | Structured metadata `{doc_id, source_tag, timestamp, ...}`. |\n",
    "| `previous_word_count` | Word count of this document or segment before it was deduplicated. |\n",
    "| `text` | The main text body extracted from the document.|\n",
    "| `url` | The original URL source of the content. Can be used for classifying content type (e.g., forums, news articles, advertising, social media, etc.). |\n",
    "| `warcinfo` | Extracted metadata from the WARC.|\n",
    "| `fasttext_openhermes_reddit_eli5_vs_rw_v2_bigram_200k_train_prob` | FastText model output indicating the likelihood this text resembles a specific user-generated corpus (computed based on bigram training probabilities). |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90dcc1f3-fd3b-4f16-a7e2-d65d907855ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- bff_contained_ngram_count_before_dedupe: long (nullable = true)\n",
      " |-- language_id_whole_page_fasttext: struct (nullable = true)\n",
      " |    |-- en: double (nullable = true)\n",
      " |-- metadata: struct (nullable = true)\n",
      " |    |-- Content-Length: string (nullable = true)\n",
      " |    |-- Content-Type: string (nullable = true)\n",
      " |    |-- WARC-Block-Digest: string (nullable = true)\n",
      " |    |-- WARC-Concurrent-To: string (nullable = true)\n",
      " |    |-- WARC-Date: string (nullable = true)\n",
      " |    |-- WARC-IP-Address: string (nullable = true)\n",
      " |    |-- WARC-Payload-Digest: string (nullable = true)\n",
      " |    |-- WARC-Record-ID: string (nullable = true)\n",
      " |    |-- WARC-Target-URI: string (nullable = true)\n",
      " |    |-- WARC-Truncated: string (nullable = true)\n",
      " |    |-- WARC-Type: string (nullable = true)\n",
      " |    |-- WARC-Warcinfo-ID: string (nullable = true)\n",
      " |-- previous_word_count: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- warcinfo: string (nullable = true)\n",
      " |-- fasttext_openhermes_reddit_eli5_vs_rw_v2_bigram_200k_train_prob: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c74eab39-11da-4d15-bc84-4cfbbd31575c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 60654\n",
      "Number of columns: 8\n"
     ]
    }
   ],
   "source": [
    "# Number of rows and columns\n",
    "num_rows = df.count()\n",
    "num_cols = len(df.columns)\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(f\"Number of columns: {num_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372e042e-cd06-4d2b-be2a-02f56a1cf9f5",
   "metadata": {},
   "source": [
    "# 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bcd526-9a24-47f9-adb0-ca7339659808",
   "metadata": {},
   "source": [
    "## 3.1 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e38a9ee-62bf-437e-92a9-1382d7dcb082",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter for non-null/non-empty text\n",
    "df = df.filter(col(\"text\").isNotNull() & (col(\"text\") != \"\"))\n",
    "\n",
    "# Rename for usability\n",
    "df = (df\n",
    "      .withColumnRenamed(\"fasttext_openhermes_reddit_eli5_vs_rw_v2_bigram_200k_train_prob\", \"user_gen_prob\")\n",
    "      .withColumnRenamed(\"language_id_whole_page_fasttext\", \"lang_en_prob\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96ca88ee-f19e-46d5-950a-3d3cabf82bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only high-confidence English content\n",
    "df = df.filter(col(\"lang_en_prob.en\") >= 0.95)\n",
    "\n",
    "# Filter low-signal/high-duplicate content\n",
    "df = df.filter(col(\"bff_contained_ngram_count_before_dedupe\") < 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a41f5a42-7a3c-4279-8d33-43c38807d5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_count\n",
    "df = df.withColumnRenamed(\"previous_word_count\", \"word_count\")\n",
    "df = df.filter(col(\"word_count\") >= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b94418d6-eeff-401e-a2aa-4ed193cc713c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(\"bff_contained_ngram_count_before_dedupe\", \"warcinfo\", \"lang_en_prob\", \"previous_word_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "013920cf-ad63-45d8-8f70-e24be965d410",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 30305\n",
      "Number of columns: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "num_rows = df.count()\n",
    "num_cols = len(df.columns)\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(f\"Number of columns: {num_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30f31c3e-442f-4902-be10-b486fd817bf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tokenisation\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    text = re.sub(r'[\\n\\r]', ' ', text)     # Remove newlines and carriage returns\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())     # Remove punctuation and lowercase\n",
    "    text = re.sub(r'\\d+', '', text)   # Remove digits\n",
    "    text = re.sub(r'\\s+', ' ', text).strip() # Normalize whitespace\n",
    "    text = demojize(text)  # Convert emojis to text (e.g., ðŸ˜Š â†’ :smiling_face:)\n",
    "    text = re.sub(r'[^\\w\\s:]', '', text.lower())  # Preserve emoji tokens\n",
    "    return text\n",
    "\n",
    "def nltk_tokenize(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return []\n",
    "    return word_tokenize(text)\n",
    "\n",
    "clean_udf = udf(clean_text, StringType())\n",
    "tokenize_udf = udf(nltk_tokenize, ArrayType(StringType()))\n",
    "\n",
    "# Clean text\n",
    "df = df.withColumn(\"clean_text\", clean_udf(col(\"text\")))\n",
    "\n",
    "# Tokenise text\n",
    "df = df.withColumn(\"tokens\", tokenize_udf(col(\"clean_text\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2aed97c-9f9d-44d0-8bc7-e251c46bca44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|            metadata|word_count|                text|                 url|       user_gen_prob|          clean_text|              tokens|\n",
      "+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|{27167, applicati...|       917|Take action now: ...|http://24ahead.co...| 0.06953519582748413|take action now t...|[take, action, no...|\n",
      "|{42807, applicati...|       909|Farris: Clampetts...|http://amarillo.c...|  0.0258486270904541|farris clampetts ...|[farris, clampett...|\n",
      "|{58953, applicati...|       179|Are the Phoenix a...|http://androidfor...| 0.10406094789505005|are the phoenix a...|[are, the, phoeni...|\n",
      "|{46857, applicati...|       597|What piracy crisi...|http://arstechnic...|  0.0899609923362732|what piracy crisi...|[what, piracy, cr...|\n",
      "|{82485, applicati...|       890|Take the 2-minute...|http://bicycles.s...|    0.64274001121521|take the minute t...|[take, the, minut...|\n",
      "|{12304, applicati...|       261|vishn010: January...|http://blog.lib.u...|0.027925968170166016|vishn january arc...|[vishn, january, ...|\n",
      "|{136635, applicat...|      4155|Friday, July 25, ...|http://blog.posit...|0.022680580615997314|friday july lazy ...|[friday, july, la...|\n",
      "|{63567, applicati...|       356|\\n\\nRetro Thursda...|http://blog.times...| 0.04710876941680908|retro thursday me...|[retro, thursday,...|\n",
      "|{104365, applicat...|      1083|HOME > Chowhound ...|http://chowhound....| 0.21541708707809448|home chowhound no...|[home, chowhound,...|\n",
      "|{92371, applicati...|       533|HOME > Chowhound ...|http://chowhound....| 0.03039240837097168|home chowhound sa...|[home, chowhound,...|\n",
      "|{136654, applicat...|      1101|HOME > Chowhound ...|http://chowhound....|  0.6440867185592651|home chowhound ho...|[home, chowhound,...|\n",
      "|{132646, applicat...|      1090|HOME > Chowhound ...|http://chowhound....| 0.07875239849090576|home chowhound sa...|[home, chowhound,...|\n",
      "|{73653, applicati...|       941|\\n\\nDont expect a...|http://cowboyszon...|0.025649607181549072|dont expect a big...|[dont, expect, a,...|\n",
      "|{2325, applicatio...|       294|Title:Â Oral Histo...|http://docsouth.u...|  0.0279616117477417|title oral histor...|[title, oral, his...|\n",
      "|{70857, applicati...|      1181|From Wikipedia, t...|http://en.wikiped...| 0.17772722244262695|from wikipedia th...|[from, wikipedia,...|\n",
      "|{43393, applicati...|      2052|Bacteria are the ...|http://everything...|  0.9043366312980652|bacteria are the ...|[bacteria, are, t...|\n",
      "|{58225, applicati...|       988|Page 1 of 2 12 La...|http://fanfiction...| 0.05114579200744629|page of lastlast ...|[page, of, lastla...|\n",
      "|{105143, applicat...|       366|Bill O'Reilly jus...|http://gawker.com...|0.021825134754180908|bill oreilly just...|[bill, oreilly, j...|\n",
      "|{100098, applicat...|       601|Brad Pitt Leaving...|http://gawker.com...| 0.42536914348602295|brad pitt leaving...|[brad, pitt, leav...|\n",
      "|{97380, applicati...|       210|Woman Who Made Ou...|http://gawker.com...|0.041969895362854004|woman who made ou...|[woman, who, made...|\n",
      "+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61eb2af-c74d-452f-83eb-281953a328d8",
   "metadata": {},
   "source": [
    "## 3.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d96e9c2-6acb-4257-b8cd-d6eb33f309f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UK banks\n",
    "BRANDS = [\"barclays\", \"lloyds\", \"natwest\", \"hsbc\", \"monzo\", \"revolut\", \"tsb\", \"santander\", \"starling\", \"nationwide\"]\n",
    "\n",
    "# Banking-related context terms to confirm brand relevance\n",
    "BANKING_CONTEXT = [\n",
    "    \"finance\", \"financial\", \"bank\", \"banking\", \"account\", \"savings\", \"current\", \"mortgage\", \"loan\", \"credit\", \"debit\", \"card\",\n",
    "    \"app\", \"mobile\", \"online\", \"branch\", \"atm\", \"transfer\", \"fees\", \"overdraft\", \"service\", \"support\"\n",
    "]\n",
    "\n",
    "# Negative context terms to exclude false positives\n",
    "NEGATIVE_CONTEXT = {\n",
    "    \"nationwide\": [\"global\", \"worldwide\", \"across the nation\", \"nationwide coverage\"],\n",
    "    \"revolut\": [\"revolution\", \"revolutionary\", \"national revolution\"],\n",
    "    \"barclays\": [\"barclays center\", \"barclays arena\"],\n",
    "    \"lloyds\": [\"lloyds of london\"],\n",
    "    \"natwest\": [],  \n",
    "    \"hsbc\": [],    \n",
    "    \"monzo\": [],   \n",
    "    \"tsb\": [],    \n",
    "    \"santander\": [], \n",
    "    \"starling\": [\"starling bird\", \"starlings\"],\n",
    "    \"nationwide\": [\"nationwide insurance\"]  # excludes US insurance company\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc51365c-7097-42de-9273-6c5e4ae472b5",
   "metadata": {},
   "source": [
    "### Extraction of Brand-related Content: *brand_name* and *mention_count*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d3b294e-9c89-49ac-84b9-f555b80b78e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+------------+-------------+\n",
      "|            metadata|word_count|                text|                 url|       user_gen_prob|          clean_text|              tokens|  brand_name|mention_count|\n",
      "+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+------------+-------------+\n",
      "|{93213, applicati...|       675|Follow Slashdot b...|http://slashdot.o...|0.059800684452056885|follow slashdot b...|[follow, slashdot...|[nationwide]|          [1]|\n",
      "|{130685, applicat...|      1743|GM CEO Mary Barra...|http://www.gmtruc...| 0.04960876703262329|gm ceo mary barra...|[gm, ceo, mary, b...|       [tsb]|          [2]|\n",
      "|{64584, applicati...|       220|The Common Good\\n...|http://www.sojo.n...| 0.09066563844680786|the common good f...|[the, common, goo...|  [barclays]|          [4]|\n",
      "|{159668, applicat...|       611|Get Connected\\n  ...|http://www.wvgaze...|0.043615520000457764|get connected fac...|[get, connected, ...|  [starling]|          [1]|\n",
      "|{73883, applicati...|      1324|Donâ€™t Pin Your Ho...|http://personalli...| 0.04557293653488159|dont pin your hop...|[dont, pin, your,...|[nationwide]|          [1]|\n",
      "|{114032, applicat...|      1678|â€¢ Fri\\n  â€¢ Dec 26...|http://www.scmp.c...|0.036042988300323486|fri dec updated a...|[fri, dec, update...|[nationwide]|          [1]|\n",
      "|{89844, applicati...|      9716|Australia Forum: ...|http://www.abc.ne...|   0.073719322681427|australia forum w...|[australia, forum...|[nationwide]|          [2]|\n",
      "|{46609, applicati...|       917|Federal judge say...|http://articles.l...| 0.04028111696243286|federal judge say...|[federal, judge, ...|[nationwide]|          [1]|\n",
      "|{70534, applicati...|      7934|Return to Transcr...|http://transcript...| 0.08446687459945679|return to transcr...|[return, to, tran...|[nationwide]|          [1]|\n",
      "|{85371, applicati...|       227|Senate Okays Dril...|http://www.mother...|0.022016584873199463|senate okays dril...|[senate, okays, d...|[nationwide]|          [1]|\n",
      "|{210886, applicat...|       827|Reliable income a...|http://www.market...|0.058073341846466064|reliable income a...|[reliable, income...|  [barclays]|          [1]|\n",
      "|{83404, applicati...|      2250|'The Hobbit' Dwar...|http://www.moview...| 0.03191119432449341|the hobbit dwarf ...|[the, hobbit, dwa...|[nationwide]|          [1]|\n",
      "|{58099, applicati...|      4300|ad info\\n\\n\\n\\n\\n...|http://transcript...|  0.1358966827392578|ad info rescues c...|[ad, info, rescue...|[nationwide]|          [1]|\n",
      "|{158715, applicat...|       347|Belfast Telegraph...|http://www.belfas...| 0.03259557485580444|belfast telegraph...|[belfast, telegra...|  [barclays]|          [1]|\n",
      "|{76463, applicati...|      7837|\\nSearch The Site...|http://www.justic...|  0.0634615421295166|search the site a...|[search, the, sit...|[nationwide]|          [1]|\n",
      "|{83782, applicati...|       509|UPDATE 2-Canada d...|http://www.cnbc.c...|0.018626153469085693|update canada did...|[update, canada, ...|       [tsb]|          [3]|\n",
      "|{210404, applicat...|      1389|About your Search...|http://archive.or...|0.046514272689819336|about your search...|[about, your, sea...|[nationwide]|          [1]|\n",
      "|{202318, applicat...|      3932|Howdy, Stranger!\\...|http://forums.edm...| 0.03286856412887573|howdy stranger to...|[howdy, stranger,...|       [tsb]|          [1]|\n",
      "|{93366, applicati...|      1266|Home Â» News\\nHome...|http://www.sltrib...|0.018371522426605225|home news home ne...|[home, news, home...|[nationwide]|          [1]|\n",
      "|{202247, applicat...|      7009|MumsnetGuestBlogs...|http://www.mumsne...|  0.0565376877784729|mumsnetguestblogs...|[mumsnetguestblog...|[nationwide]|          [1]|\n",
      "+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_brands_and_counts(text):\n",
    "    if not isinstance(text, str):\n",
    "        return [], []\n",
    "    text_lower = text.lower()\n",
    "    tokens = word_tokenize(text_lower)\n",
    "    \n",
    "    brands_found = []\n",
    "    counts = []\n",
    "    \n",
    "    for brand in BRANDS:\n",
    "        # Initialize count\n",
    "        brand_count = 0\n",
    "        \n",
    "        # Check for brand in tokens with word boundaries\n",
    "        brand_pattern = r'\\b' + re.escape(brand) + r'\\b'\n",
    "        matches = re.findall(brand_pattern, text_lower)\n",
    "        brand_count += len(matches)\n",
    "        \n",
    "        # Validate with banking context (at least one banking term nearby)\n",
    "        has_banking_context = False\n",
    "        for context in BANKING_CONTEXT:\n",
    "            if context in text_lower:\n",
    "                has_banking_context = True\n",
    "                break\n",
    "        \n",
    "        # Check for negative context to exclude false positives\n",
    "        has_negative_context = False\n",
    "        for negative_term in NEGATIVE_CONTEXT.get(brand, []):\n",
    "            if negative_term in text_lower:\n",
    "                has_negative_context = True\n",
    "                break\n",
    "        \n",
    "        # Only include brand if it has banking context and no negative context\n",
    "        if brand_count > 0 and has_banking_context and not has_negative_context:\n",
    "            brands_found.append(brand)\n",
    "            counts.append(brand_count)\n",
    "    \n",
    "    return brands_found, counts\n",
    "\n",
    "@udf(ArrayType(StringType()))\n",
    "def extract_brands(text):\n",
    "    brands, _ = extract_brands_and_counts(text)\n",
    "    return brands\n",
    "\n",
    "@udf(ArrayType(IntegerType()))\n",
    "def extract_mention_counts(text):\n",
    "    _, counts = extract_brands_and_counts(text)\n",
    "    return counts\n",
    "\n",
    "df = df.withColumn(\"brand_name\", extract_brands(col(\"clean_text\")))\n",
    "df = df.withColumn(\"mention_count\", extract_mention_counts(col(\"clean_text\")))\n",
    "\n",
    "# Filter rows with at least one valid brand mention\n",
    "df = df.filter(col(\"brand_name\").isNotNull() & (col(\"brand_name\").getItem(0).isNotNull()))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a936d1f-4f0b-4cf2-ab62-954072ff8ee7",
   "metadata": {},
   "source": [
    "### *url_domain*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f95a49c7-494f-4ccc-a6a8-ebbcdaa0ea04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url_domain\n",
    "@udf(StringType())\n",
    "def extract_domain(url):\n",
    "    if not isinstance(url, str):\n",
    "        return \"\"\n",
    "    parsed = urlparse(url)\n",
    "    return parsed.netloc or \"\"\n",
    "\n",
    "df = df.withColumn(\"url_domain\", extract_domain(col(\"url\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fc79bb-4756-4944-a900-488ed54c2e3f",
   "metadata": {},
   "source": [
    "### Classification of Brand-related Content: *content_type*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b1b9dd-d7ff-4578-a2bc-52660a847a95",
   "metadata": {},
   "source": [
    "Filtering by content_type can refine the dataset for sentiment-focused LLM training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da944af8-ed57-496b-add8-1116f299352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_content(url, prob, text, content_type):\n",
    "    if not isinstance(url, str):\n",
    "        url = \"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = \"\"\n",
    "    if not isinstance(content_type, str):\n",
    "        content_type = \"\"\n",
    "    \n",
    "    url = url.lower()\n",
    "    text = text.lower()\n",
    "    content_type = content_type.lower()\n",
    "    prob = prob if prob is not None else 0.0\n",
    "    \n",
    "    # Social media: High FastText score or social platforms\n",
    "    social_media_domains = [\n",
    "        \"reddit\", \"twitter\", \"x.com\", \"facebook\", \"linkedin\", \"instagram\",\n",
    "        \"tiktok\", \"pinterest\", \"forum\", \"discuss\", \"community\"\n",
    "    ]\n",
    "    if prob >= 0.5 or any(domain in url for domain in social_media_domains):\n",
    "        return \"user_generated\"\n",
    "    \n",
    "    # News article: Reputable news sources\n",
    "    news_domains = [\n",
    "        \"bbc\", \"guardian\", \"telegraph\", \"ft.com\", \"reuters\", \"bloomberg\",\n",
    "        \"cnn\", \"nytimes\", \"independent\", \"dailymail\", \"sky.com\", \"news\"\n",
    "    ]\n",
    "    if any(domain in url for domain in news_domains) or \"news\" in text:\n",
    "        return \"news_article\"\n",
    "    \n",
    "    # Customer review: Review platforms or review-related keywords\n",
    "    review_domains = [\"trustpilot\", \"feefo\", \"reviews\", \"yelp\", \"google.com/reviews\"]\n",
    "    review_keywords = [\"review\", \"rated\", \"rating\", \"customer feedback\", \"complaint\", \"testimonial\"]\n",
    "    if any(domain in url for domain in review_domains) or any(keyword in text for keyword in review_keywords):\n",
    "        return \"customer_review\"\n",
    "    \n",
    "    # Blog post: Blog platforms or keywords\n",
    "    blog_domains = [\"medium\", \"wordpress\", \"blogger\", \"tumblr\", \"substack\"]\n",
    "    blog_keywords = [\"blog\", \"post\", \"article by\", \"opinion piece\"]\n",
    "    if any(domain in url for domain in blog_domains) or any(keyword in text for keyword in blog_keywords):\n",
    "        return \"blog_post\"\n",
    "    \n",
    "    # Regulatory document: Official or compliance-related sources\n",
    "    regulatory_domains = [\"fca.org.uk\", \"bankofengland\", \"gov.uk\", \"regulations\", \"compliance\"]\n",
    "    if any(domain in url for domain in regulatory_domains) or content_type == \"application/pdf\":\n",
    "        return \"regulatory_document\"\n",
    "    \n",
    "    # Advertising content: Promotional keywords\n",
    "    advertising_keywords = [\"ads\", \"campaign\", \"promo\", \"sponsor\", \"advert\", \"promotion\"]\n",
    "    if any(term in url for term in advertising_keywords) or any(term in text for term in advertising_keywords):\n",
    "        return \"advertising_content\"\n",
    "    \n",
    "    # Owned media: Brand or institutional domains\n",
    "    owned_media_domains = [\n",
    "        \"gov.uk\", \"ac.uk\", \"co.uk\", \"barclays\", \"lloyds\", \"natwest\", \"hsbc\",\n",
    "        \"monzo\", \"revolut\", \"tsb\", \"santander\", \"starling\", \"nationwide\"\n",
    "    ]\n",
    "    if any(domain in url for domain in owned_media_domains):\n",
    "        return \"owned_media\"\n",
    "    \n",
    "    # Forum post: Specific forum platforms\n",
    "    forum_domains = [\"moneysavingexpert\", \"thestudentroom\", \"forums\", \"discussion\"]\n",
    "    if any(domain in url for domain in forum_domains) and prob >= 0.3:\n",
    "        return \"forum_post\"\n",
    "    \n",
    "    # FAQ/Knowledge base: Support or informational pages\n",
    "    faq_keywords = [\"faq\", \"help\", \"support\", \"knowledge base\", \"how to\", \"guide\"]\n",
    "    if any(keyword in url for keyword in faq_keywords) or any(keyword in text for keyword in faq_keywords):\n",
    "        return \"faq_knowledge_base\"\n",
    "    \n",
    "    # Default: Other\n",
    "    return \"miscellaneous\"\n",
    "\n",
    "content_type_udf = udf(classify_content, StringType())\n",
    "df = df.withColumn(\"content_type\", content_type_udf(\n",
    "    col(\"url\"),\n",
    "    col(\"user_gen_prob\"),\n",
    "    col(\"clean_text\"),\n",
    "    col(\"metadata.Content-Type\")\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80381bd0-c90e-4d04-a561-f606a6f94e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+------------+-------------+--------------------+-------------------+\n",
      "|            metadata|word_count|                text|                 url|       user_gen_prob|          clean_text|              tokens|  brand_name|mention_count|          url_domain|       content_type|\n",
      "+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+------------+-------------+--------------------+-------------------+\n",
      "|{93213, applicati...|       675|Follow Slashdot b...|http://slashdot.o...|0.059800684452056885|follow slashdot b...|[follow, slashdot...|[nationwide]|          [1]|        slashdot.org|          blog_post|\n",
      "|{130685, applicat...|      1743|GM CEO Mary Barra...|http://www.gmtruc...| 0.04960876703262329|gm ceo mary barra...|[gm, ceo, mary, b...|       [tsb]|          [2]| www.gmtruckclub.com|     user_generated|\n",
      "|{64584, applicati...|       220|The Common Good\\n...|http://www.sojo.n...| 0.09066563844680786|the common good f...|[the, common, goo...|  [barclays]|          [4]|        www.sojo.net|    customer_review|\n",
      "|{159668, applicat...|       611|Get Connected\\n  ...|http://www.wvgaze...|0.043615520000457764|get connected fac...|[get, connected, ...|  [starling]|          [1]|   www.wvgazette.com|       news_article|\n",
      "|{73883, applicati...|      1324|Donâ€™t Pin Your Ho...|http://personalli...| 0.04557293653488159|dont pin your hop...|[dont, pin, your,...|[nationwide]|          [1]| personalliberty.com|       news_article|\n",
      "|{114032, applicat...|      1678|â€¢ Fri\\n  â€¢ Dec 26...|http://www.scmp.c...|0.036042988300323486|fri dec updated a...|[fri, dec, update...|[nationwide]|          [1]|        www.scmp.com|       news_article|\n",
      "|{89844, applicati...|      9716|Australia Forum: ...|http://www.abc.ne...|   0.073719322681427|australia forum w...|[australia, forum...|[nationwide]|          [2]|      www.abc.net.au|     user_generated|\n",
      "|{46609, applicati...|       917|Federal judge say...|http://articles.l...| 0.04028111696243286|federal judge say...|[federal, judge, ...|[nationwide]|          [1]|articles.latimes.com|          blog_post|\n",
      "|{70534, applicati...|      7934|Return to Transcr...|http://transcript...| 0.08446687459945679|return to transcr...|[return, to, tran...|[nationwide]|          [1]| transcripts.cnn.com|       news_article|\n",
      "|{85371, applicati...|       227|Senate Okays Dril...|http://www.mother...|0.022016584873199463|senate okays dril...|[senate, okays, d...|[nationwide]|          [1]| www.motherjones.com| faq_knowledge_base|\n",
      "|{210886, applicat...|       827|Reliable income a...|http://www.market...|0.058073341846466064|reliable income a...|[reliable, income...|  [barclays]|          [1]| www.marketwatch.com|advertising_content|\n",
      "|{83404, applicati...|      2250|'The Hobbit' Dwar...|http://www.moview...| 0.03191119432449341|the hobbit dwarf ...|[the, hobbit, dwa...|[nationwide]|          [1]|    www.movieweb.com|advertising_content|\n",
      "|{58099, applicati...|      4300|ad info\\n\\n\\n\\n\\n...|http://transcript...|  0.1358966827392578|ad info rescues c...|[ad, info, rescue...|[nationwide]|          [1]| transcripts.cnn.com|       news_article|\n",
      "|{158715, applicat...|       347|Belfast Telegraph...|http://www.belfas...| 0.03259557485580444|belfast telegraph...|[belfast, telegra...|  [barclays]|          [1]|www.belfasttelegr...|       news_article|\n",
      "|{76463, applicati...|      7837|\\nSearch The Site...|http://www.justic...|  0.0634615421295166|search the site a...|[search, the, sit...|[nationwide]|          [1]|     www.justice.gov|       news_article|\n",
      "|{83782, applicati...|       509|UPDATE 2-Canada d...|http://www.cnbc.c...|0.018626153469085693|update canada did...|[update, canada, ...|       [tsb]|          [3]|        www.cnbc.com|       news_article|\n",
      "|{210404, applicat...|      1389|About your Search...|http://archive.or...|0.046514272689819336|about your search...|[about, your, sea...|[nationwide]|          [1]|         archive.org|    customer_review|\n",
      "|{202318, applicat...|      3932|Howdy, Stranger!\\...|http://forums.edm...| 0.03286856412887573|howdy stranger to...|[howdy, stranger,...|       [tsb]|          [1]|  forums.edmunds.com|     user_generated|\n",
      "|{93366, applicati...|      1266|Home Â» News\\nHome...|http://www.sltrib...|0.018371522426605225|home news home ne...|[home, news, home...|[nationwide]|          [1]|      www.sltrib.com|       news_article|\n",
      "|{202247, applicat...|      7009|MumsnetGuestBlogs...|http://www.mumsne...|  0.0565376877784729|mumsnetguestblogs...|[mumsnetguestblog...|[nationwide]|          [1]|     www.mumsnet.com|    customer_review|\n",
      "+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+------------+-------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02f787e-bf6f-418e-b2cc-fa2944f81a44",
   "metadata": {},
   "source": [
    "### Temporal columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1e109a0-8031-46bd-9f62-1fd981fb1c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"date\", to_date(col(\"metadata.WARC-Date\")))\n",
    "df = df.withColumn(\"day\", dayofmonth(col(\"date\")))\n",
    "df = df.withColumn(\"month\", month(col(\"date\")))\n",
    "df = df.withColumn(\"year\", year(col(\"date\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88fbd2f-0c33-44ee-92e6-1c285dcce9b1",
   "metadata": {},
   "source": [
    "### Drop Irrelevant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f548a426-b1db-474e-8d12-39985e15bbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"user_gen_prob\", \"metadata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab61e44-9a38-4c42-9578-61148f0f1cdf",
   "metadata": {},
   "source": [
    "### Summary of Final Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2201b9-0c3c-48de-8534-299eac595447",
   "metadata": {},
   "source": [
    "| Column Name         | Data Type          | Description                                      |\n",
    "|---------------------|--------------------|--------------------------------------------------|\n",
    "| `brand_name`        | Array of String    | List of UK bank brands mentioned in the text (e.g., [\"barclays\", \"nationwide\"]) |\n",
    "| `mention_count`     | Array of Integer   | Number of mentions for each brand in `brand_name` (e.g., [2, 1]) |\n",
    "| `content_type`      | String             | Classification of content (e.g., social_media, news_article, customer_review) |\n",
    "| `raw_text`          | String             | Original, unprocessed text from the dataset       |\n",
    "| `clean_text`        | String             | Preprocessed text for analysis (lowercase, no punctuation) |\n",
    "| `tokens`            | Array of String    | Tokenized words from `clean_text` for further processing |\n",
    "| `url`               | String             | Original URL of the content source               |\n",
    "| `url_domain`        | String             | Root domain extracted from `url` (e.g., x.com)   |\n",
    "| `word_count`        | Long               | Number of words in the content                   |\n",
    "| `date`              | Date               | Full crawl timestamp (e.g., 2024-11-24)          |\n",
    "| `day`               | Integer            | Day of the month from metadata        |\n",
    "| `month`             | Integer            | Month from crawl metadata                   |\n",
    "| `year`              | Integer            | Year from crawl metadata                    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ac84abe-c6e2-4bdb-bfbd-08dbc313ccd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- brand_name: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- mention_count: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      " |-- content_type: string (nullable = true)\n",
      " |-- raw_text: string (nullable = true)\n",
      " |-- clean_text: string (nullable = true)\n",
      " |-- tokens: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- url_domain: string (nullable = true)\n",
      " |-- word_count: long (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.selectExpr(\n",
    "    \"brand_name\",\n",
    "    \"mention_count\",\n",
    "    \"content_type\",\n",
    "    \"text AS raw_text\",\n",
    "    \"clean_text\",\n",
    "    \"tokens\",\n",
    "    \"url\",\n",
    "    \"url_domain\",\n",
    "    \"word_count\",\n",
    "    \"date\",\n",
    "    \"day\",\n",
    "    \"month\",\n",
    "    \"year\",\n",
    ")\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d7f73ee-3936-44db-9ca3-ccc040a18ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2073e99-1894-41c8-8049-df3d9423f525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[brand_name: array<string>, mention_count: array<int>, content_type: string, raw_text: string, clean_text: string, tokens: array<string>, url: string, url_domain: string, word_count: bigint, date: date, day: int, month: int, year: int]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10282244-9c6a-429c-b667-0283e329b34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_rows = df.count()\n",
    "# num_cols = len(df.columns)\n",
    "# print(f\"Number of rows: {num_rows}\")\n",
    "# print(f\"Number of columns: {num_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361545ab-175d-4f82-83f4-6b96a4e415ea",
   "metadata": {},
   "source": [
    "# 4. Brand Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc797f4e-2979-456e-a957-9ece9bead94d",
   "metadata": {},
   "source": [
    "In this section, sentiment analysis is performed on UK bank brand mentions using a hybrid approach combining lexicon-based (VADER) and a transformer-based model (FinBERT)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddc612b-d46d-4533-ad51-98fd21e17a1d",
   "metadata": {},
   "source": [
    "### 4.1 Lexicon-Based (VADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66693a6c-a05e-4cb8-bf68-a1df14046f1e",
   "metadata": {},
   "source": [
    "The following code performs brand sentiment analysis using NLTK's VADER (Valence Aware Dictionary and sEntiment Reasoner), a lexicon-based tool specifically designed for detecting sentiment in user-generated texts.\n",
    "\n",
    "VADER calculates 4 sentiment metrics for each text input:\n",
    "- `vader_score` (compound score): A normalized weighted composite score ranging from -1 (negative) to +1 (positive). Derived from the sum of valence scores of individual words, adjusted for modifiers (e.g., \"very good\" amplifies positivity).\n",
    "- `positive_score`, `neutral_score`, `negative_score`: Proportional metrics representing the text's positive, neutral, and negative sentiment (each ranges 0â€“1). The 3 scores sum to 1.\n",
    "\n",
    "`sentiment_label` is assigned based on the compound `vader_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd2c849d-24bf-419f-b5ca-f52aa83f6329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise VADER\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Calculates VADER sentiment\n",
    "def vader_sentiment(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return {\"compound\": 0.0, \"positive\": 0.0, \"neutral\": 0.0, \"negative\": 0.0}\n",
    "    scores = sid.polarity_scores(text)\n",
    "    return scores\n",
    "\n",
    "# Schema for VADER output\n",
    "vader_schema = StructType([\n",
    "    StructField(\"compound\", FloatType(), nullable=True),\n",
    "    StructField(\"pos\", FloatType(), nullable=True),\n",
    "    StructField(\"neu\", FloatType(), nullable=True),\n",
    "    StructField(\"neg\", FloatType(), nullable=True)\n",
    "])\n",
    "\n",
    "vader_udf = udf(vader_sentiment, vader_schema)\n",
    "df = df.withColumn(\"vader_sentiment\", vader_udf(col(\"clean_text\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cad9ef-fa39-4cbf-9fd3-8113e4ded011",
   "metadata": {},
   "source": [
    "### Sentiment Scores and Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7ae339e-8252-43e9-8e5f-8e5991cc193d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VADER Sentiment Scores and Labels:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+------------------+--------------------------------------------------+--------------------+-----------+--------------+-------------+--------------+---------------+\n",
      "|  brand_name|mention_count|      content_type|                                        clean_text|          url_domain|vader_score|positive_score|neutral_score|negative_score|sentiment_label|\n",
      "+------------+-------------+------------------+--------------------------------------------------+--------------------+-----------+--------------+-------------+--------------+---------------+\n",
      "|[nationwide]|          [1]|         blog_post|follow slashdot blog updates by subscribing to ...|        slashdot.org|     0.9943|         0.175|        0.711|         0.114|       Positive|\n",
      "|       [tsb]|          [2]|    user_generated|gm ceo mary barra congressional hearings on rec...| www.gmtruckclub.com|    -0.9969|         0.074|         0.82|         0.106|       Negative|\n",
      "|  [barclays]|          [4]|   customer_review|the common good former barclays ceo feels respo...|        www.sojo.net|     0.9588|         0.131|        0.816|         0.053|       Positive|\n",
      "|  [starling]|          [1]|      news_article|get connected facebook twitter sign in classifi...|   www.wvgazette.com|    -0.9876|         0.074|        0.814|         0.112|       Negative|\n",
      "|[nationwide]|          [1]|      news_article|dont pin your hopes on the party of lincoln rep...| personalliberty.com|     0.9885|         0.111|        0.815|         0.074|       Positive|\n",
      "|[nationwide]|          [1]|      news_article|fri dec updated am letters to the editor decemb...|        www.scmp.com|    -0.9182|         0.091|         0.82|         0.089|       Negative|\n",
      "|[nationwide]|          [2]|    user_generated|australia forum whats a nice girl like you doin...|      www.abc.net.au|     0.9999|         0.132|        0.782|         0.086|       Positive|\n",
      "|[nationwide]|          [1]|         blog_post|federal judge says healthcare law is unconstitu...|articles.latimes.com|     0.4692|         0.077|        0.848|         0.075|       Positive|\n",
      "|[nationwide]|          [1]|      news_article|return to transcripts main page more details to...| transcripts.cnn.com|     0.9989|         0.103|        0.812|         0.085|       Positive|\n",
      "|[nationwide]|          [1]|faq_knowledge_base|senate okays drilling in the gulf of mexico or ...| www.motherjones.com|    -0.4588|         0.045|        0.893|         0.062|       Negative|\n",
      "+------------+-------------+------------------+--------------------------------------------------+--------------------+-----------+--------------+-------------+--------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"vader_score\", col(\"vader_sentiment.compound\"))\n",
    "df = df.withColumn(\"positive_score\", col(\"vader_sentiment.pos\"))\n",
    "df = df.withColumn(\"neutral_score\", col(\"vader_sentiment.neu\"))\n",
    "df = df.withColumn(\"negative_score\", col(\"vader_sentiment.neg\"))\n",
    "\n",
    "# Sentiment Label\n",
    "df = df.withColumn(\"sentiment_label\",\n",
    "    when(col(\"vader_score\") > 0.05, \"Positive\")\n",
    "    .when(col(\"vader_score\") < -0.05, \"Negative\")\n",
    "    .otherwise(\"Neutral\"))\n",
    "\n",
    "df = df.drop(\"vader_sentiment\")\n",
    "\n",
    "print(\"\\nVADER Sentiment Scores and Labels:\")\n",
    "df.select(\n",
    "    \"brand_name\", \"mention_count\", \"content_type\", \"clean_text\", \"url_domain\", \"vader_score\", \"positive_score\",\n",
    "    \"neutral_score\", \"negative_score\", \"sentiment_label\"\n",
    ").show(10, truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7562f17-23e8-4cc6-aa44-0897c3c5195d",
   "metadata": {},
   "source": [
    "### Overall Sentiment Aggregation: *avg_vader_score*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f3457c5-852e-453e-b311-d970f13a236e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VADER Sentiment Summary by Brand and Content Type:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:=============================>                            (1 + 1) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+---------------------+-------------------+\n",
      "|brand     |content_type       |avg_vader_score      |avg_sentiment_label|\n",
      "+----------+-------------------+---------------------+-------------------+\n",
      "|barclays  |advertising_content|0.9957000017166138   |Positive           |\n",
      "|barclays  |blog_post          |0.9683666825294495   |Positive           |\n",
      "|barclays  |customer_review    |-0.03514999896287918 |Neutral            |\n",
      "|barclays  |faq_knowledge_base |0.9692499935626984   |Positive           |\n",
      "|barclays  |miscellaneous      |-0.005349993705749512|Neutral            |\n",
      "|barclays  |news_article       |0.4425363654101437   |Positive           |\n",
      "|hsbc      |advertising_content|0.9905000030994415   |Positive           |\n",
      "|hsbc      |customer_review    |-0.38639998994767666 |Negative           |\n",
      "|hsbc      |news_article       |0.6585272780873559   |Positive           |\n",
      "|lloyds    |customer_review    |-0.34596999883651736 |Negative           |\n",
      "|lloyds    |miscellaneous      |-0.98539999127388    |Negative           |\n",
      "|lloyds    |news_article       |0.5722583352277676   |Positive           |\n",
      "|lloyds    |user_generated     |0.9997000098228455   |Positive           |\n",
      "|nationwide|advertising_content|0.39048499464988706  |Positive           |\n",
      "|nationwide|blog_post          |0.10452142570699964  |Positive           |\n",
      "|nationwide|customer_review    |0.5889523791681442   |Positive           |\n",
      "|nationwide|faq_knowledge_base |0.4216500052383968   |Positive           |\n",
      "|nationwide|miscellaneous      |0.2771181897683577   |Positive           |\n",
      "|nationwide|news_article       |0.17134878425518188  |Positive           |\n",
      "|nationwide|owned_media        |-0.12655001878738403 |Negative           |\n",
      "+----------+-------------------+---------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Associates sentiment with each brand\n",
    "df_exploded = df.select(\n",
    "    explode(col(\"brand_name\")).alias(\"brand\"),\n",
    "    col(\"vader_score\"),\n",
    "    col(\"content_type\"),\n",
    "    col(\"year\"),\n",
    "    col(\"month\"),\n",
    "    col(\"day\")\n",
    ")\n",
    "\n",
    "# Sentiment by brand and content_type\n",
    "sentiment_summary = df_exploded.groupBy(\"brand\", \"content_type\").agg(\n",
    "    avg(\"vader_score\").alias(\"avg_vader_score\")\n",
    ").orderBy(\"brand\", \"content_type\")\n",
    "\n",
    "# Sentiment label\n",
    "sentiment_summary = sentiment_summary.withColumn(\n",
    "    \"avg_sentiment_label\",\n",
    "    when(col(\"avg_vader_score\") > 0.05, \"Positive\")\n",
    "    .when(col(\"avg_vader_score\") < -0.05, \"Negative\")\n",
    "    .otherwise(\"Neutral\")\n",
    ")\n",
    "\n",
    "print(\"VADER Sentiment Summary by Brand and Content Type:\")\n",
    "sentiment_summary.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476f54a9-a9d0-4f70-9ce3-48909f170f43",
   "metadata": {},
   "source": [
    "### 4.2 Transformer-Based\n",
    "**FinBERT** model is implemented for brand sentiment analysis of UK financial services brands due to its:\n",
    "- Domain-specialisation:  Explicitly trained on financial texts (10M+ finance docs), including financial news, analyst reports, earnings call transcripts, SEC/FCA filings, and other regulatory documents. It has good understanding of key financial concepts, such as, financial metrics, market movements, and regulatory language.\n",
    "- Sentiment granularity: 3-class (positive/neutral/negative)\n",
    "- Numerical sensitivity: Handles earnings and percentages well.\n",
    "  \n",
    "The following outputs are computed:\n",
    "- `finbert_label` â€“ the sentiment class with the highest average probability across all chunks\n",
    "- `finbert_score` â€“ the sentiment polarity score, calculated as Positive - Negative probability.\n",
    "- `finbert_confidence`: How confident FinBERT is about its prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6863e15-59d1-41de-8028-0c80247b4906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "/opt/conda/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# FinBERT tokenizer and model\n",
    "finbert_tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\", use_fast=True)\n",
    "finbert_model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\").to(device)\n",
    "finbert_pipeline = pipeline(\n",
    "    task=\"sentiment-analysis\",\n",
    "    model=finbert_model,\n",
    "    tokenizer=finbert_tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1,\n",
    "    torch_dtype=torch.float16,\n",
    "    return_all_scores=True,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=512,\n",
    "    batch_size=32\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c0deaf6-c496-44b2-93d0-e43e97fd9f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_chunks(text, tokenizer):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return [\"\"]\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), 510):  # 510 to allow for special tokens\n",
    "        chunk_tokens = tokens[i:i + 510]\n",
    "        chunk_text = tokenizer.convert_tokens_to_string(chunk_tokens)\n",
    "        chunks.append(chunk_text)\n",
    "    return chunks if chunks else [\"\"]\n",
    "    \n",
    "def analyze_finbert(text):\n",
    "    try:\n",
    "        chunks = prepare_chunks(text, finbert_tokenizer)\n",
    "        if not chunks or all(not c.strip() for c in chunks):\n",
    "            return \"neutral\", 0.0, 0.0, {\"positive\": 0.0, \"neutral\": 1.0, \"negative\": 0.0}\n",
    "\n",
    "        results = finbert_pipeline(chunks)\n",
    "        cumulative_scores = {\"positive\": 0.0, \"neutral\": 0.0, \"negative\": 0.0}\n",
    "        confidences = []\n",
    "        count = 0\n",
    "\n",
    "        for r in results:\n",
    "            if isinstance(r, list):\n",
    "                for entry in r:\n",
    "                    label = entry[\"label\"].lower()\n",
    "                    score = entry[\"score\"]\n",
    "                    cumulative_scores[label] += score\n",
    "                confidences.append(max(entry[\"score\"] for entry in r))\n",
    "                count += 1\n",
    "\n",
    "        if count == 0:\n",
    "            return \"neutral\", 0.0, 0.0, {\"positive\": 0.0, \"neutral\": 1.0, \"negative\": 0.0}\n",
    "\n",
    "        # Normalises all the scores\n",
    "        avg_scores = {k: v / count for k, v in cumulative_scores.items()}\n",
    "        avg_confidence = sum(confidences) / count\n",
    "\n",
    "        # Polarity score\n",
    "        polarity = avg_scores[\"positive\"] - avg_scores[\"negative\"]\n",
    "\n",
    "        # Final predicted label\n",
    "        if abs(polarity) < 0.15:\n",
    "            final_label = \"neutral\"\n",
    "        else:\n",
    "            final_label = \"positive\" if polarity > 0 else \"negative\"\n",
    "\n",
    "        return (\n",
    "            final_label,\n",
    "            round(polarity, 4),\n",
    "            round(avg_confidence, 4),\n",
    "            {k: round(v, 4) for k, v in avg_scores.items()}\n",
    "        )\n",
    "\n",
    "    except torch.cuda.OutOfMemoryError:\n",
    "        torch.cuda.empty_cache()\n",
    "        return analyze_finbert_vader_style(text)\n",
    "    except Exception as e:\n",
    "        print(f\"FinBERT error on text {text[:50]}...: {str(e)}\")\n",
    "        return \"neutral\", 0.0, 0.0, {\"positive\": 0.0, \"neutral\": 1.0, \"negative\": 0.0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db7dfe27-a1a2-42b5-8049-78561aab2a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Filter and truncate text\n",
    "df = df.filter(col(\"clean_text\").isNotNull() & col(\"clean_text\").cast(\"string\").isNotNull())\n",
    "df = df.withColumn(\"clean_text\", substring(col(\"clean_text\"), 1, 512))\n",
    "df.cache()\n",
    "\n",
    "# Row index for joining\n",
    "df = df.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "\n",
    "# Convert to Pandas for transformer processing\n",
    "pandas_df = df.select(\"row_id\", \"clean_text\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "157d0994-d7cc-448d-8983-803e16458234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute analysis\n",
    "finbert_results = [analyze_finbert(text) for text in pandas_df[\"clean_text\"]]\n",
    "\n",
    "# Sentiment label, score and confidence\n",
    "pandas_df[\"finbert_label\"] = [r[0] for r in finbert_results]\n",
    "pandas_df[\"finbert_score\"] = [r[1] for r in finbert_results]\n",
    "pandas_df[\"finbert_confidence\"] = [r[2] for r in finbert_results]\n",
    "\n",
    "# Individual sentiment scores\n",
    "pandas_df[\"finbert_dist_positive\"] = [r[3][\"positive\"] for r in finbert_results]\n",
    "pandas_df[\"finbert_dist_neutral\"] = [r[3][\"neutral\"] for r in finbert_results]\n",
    "pandas_df[\"finbert_dist_negative\"] = [r[3][\"negative\"] for r in finbert_results]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e03afd9b-6a24-42d2-af00-080bb2422fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Displaying DataFrame after transformer processing:\n",
      "+------------+-------------+---------------+--------------------------------------------------+-------------+-------------+------------------+---------------------+--------------------+---------------------+\n",
      "|  brand_name|mention_count|   content_type|                                        clean_text|finbert_label|finbert_score|finbert_confidence|finbert_dist_positive|finbert_dist_neutral|finbert_dist_negative|\n",
      "+------------+-------------+---------------+--------------------------------------------------+-------------+-------------+------------------+---------------------+--------------------+---------------------+\n",
      "|[nationwide]|          [1]|      blog_post|follow slashdot blog updates by subscribing to ...|      neutral|      -0.1004|            0.8547|               0.0225|              0.8547|               0.1228|\n",
      "|       [tsb]|          [2]| user_generated|gm ceo mary barra congressional hearings on rec...|      neutral|      -0.1355|            0.7914|               0.0366|              0.7914|               0.1721|\n",
      "|  [barclays]|          [4]|customer_review|the common good former barclays ceo feels respo...|     negative|      -0.7265|            0.7617|               0.0352|              0.2031|               0.7617|\n",
      "|  [starling]|          [1]|   news_article|get connected facebook twitter sign in classifi...|      neutral|      -0.0539|            0.8891|               0.0285|              0.8891|               0.0824|\n",
      "|[nationwide]|          [1]|   news_article|dont pin your hopes on the party of lincoln rep...|      neutral|      -0.0384|             0.877|               0.0423|               0.877|               0.0807|\n",
      "+------------+-------------+---------------+--------------------------------------------------+-------------+-------------+------------------+---------------------+--------------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "finbert_csv = \"data/finbert_results.csv\"\n",
    "pandas_df[[\n",
    "    \"row_id\", \"finbert_label\", \"finbert_score\", \"finbert_confidence\",\n",
    "    \"finbert_dist_positive\", \"finbert_dist_neutral\", \"finbert_dist_negative\"\n",
    "]].to_csv(finbert_csv, index=False)\n",
    "\n",
    "# Transform back to Spark\n",
    "transformer_df = spark.read.csv(finbert_csv, header=True, inferSchema=True)\n",
    "df = df.join(transformer_df, \"row_id\").drop(\"row_id\")\n",
    "\n",
    "print(\"\\nDisplaying DataFrame after transformer processing:\")\n",
    "df.select(\n",
    "    \"brand_name\", \"mention_count\", \"content_type\", \"clean_text\",\n",
    "    \"finbert_label\", \"finbert_score\", \"finbert_confidence\", \"finbert_dist_positive\", \"finbert_dist_neutral\", \"finbert_dist_negative\"\n",
    ").show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa12fe9f-5d83-4110-8e25-10d51f26f89a",
   "metadata": {},
   "source": [
    "## 4.3 Hybrid Sentiment Analysis\n",
    "The following section combines VADER and FinBERT predictions, weighted by `content_type`. VADER is up-weighted for `user_generated` and `customer_review`, and FinBERT for `news_article` and `regulatory_document`. This outputs `hybrid_sentiment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7bdb59e2-c8c4-451a-a1d1-8be9e6ffa39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(StringType())\n",
    "def hybrid_sentiment(vader_score, finbert_score, content_type):\n",
    "    if vader_score is None or finbert_score is None:\n",
    "        return \"Neutral\"\n",
    "    \n",
    "    # Adjusted weights (sum to 1)\n",
    "    if content_type in [\"user_generated\", \"customer_review\", \"forum_post\"]:\n",
    "        weights = {\"vader\": 0.6, \"finbert\": 0.4}\n",
    "    elif content_type in [\"news_article\", \"regulatory_document\"]:\n",
    "        weights = {\"vader\": 0.3, \"finbert\": 0.7}\n",
    "    else:\n",
    "        weights = {\"vader\": 0.5, \"finbert\": 0.5}\n",
    "    \n",
    "    combined_score = (\n",
    "        weights[\"vader\"] * vader_score +\n",
    "        weights[\"finbert\"] * finbert_score\n",
    "    )\n",
    "    \n",
    "    if combined_score > 0.05:\n",
    "        return \"Positive\"\n",
    "    elif combined_score < -0.05:\n",
    "        return \"Negative\"\n",
    "    return \"Neutral\"\n",
    "\n",
    "df = df.withColumn(\"hybrid_sentiment\", hybrid_sentiment(\n",
    "    col(\"vader_score\"),\n",
    "    col(\"finbert_score\"),\n",
    "    col(\"content_type\")\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5ffa6e3-432b-4713-abff-9d85e8157c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+------------------+--------------------------------------------------+----------------+-----------+-------------+\n",
      "|  brand_name|mention_count|      content_type|                                        clean_text|hybrid_sentiment|vader_score|finbert_score|\n",
      "+------------+-------------+------------------+--------------------------------------------------+----------------+-----------+-------------+\n",
      "|[nationwide]|          [1]|         blog_post|follow slashdot blog updates by subscribing to ...|        Positive|     0.9943|      -0.1004|\n",
      "|       [tsb]|          [2]|    user_generated|gm ceo mary barra congressional hearings on rec...|        Negative|    -0.9969|      -0.1355|\n",
      "|  [barclays]|          [4]|   customer_review|the common good former barclays ceo feels respo...|        Positive|     0.9588|      -0.7265|\n",
      "|  [starling]|          [1]|      news_article|get connected facebook twitter sign in classifi...|        Negative|    -0.9876|      -0.0539|\n",
      "|[nationwide]|          [1]|      news_article|dont pin your hopes on the party of lincoln rep...|        Positive|     0.9885|      -0.0384|\n",
      "|[nationwide]|          [1]|      news_article|fri dec updated am letters to the editor decemb...|        Positive|    -0.9182|       0.8481|\n",
      "|[nationwide]|          [2]|    user_generated|australia forum whats a nice girl like you doin...|        Positive|     0.9999|       0.0177|\n",
      "|[nationwide]|          [1]|         blog_post|federal judge says healthcare law is unconstitu...|         Neutral|     0.4692|      -0.4807|\n",
      "|[nationwide]|          [1]|      news_article|return to transcripts main page more details to...|        Positive|     0.9989|       -0.052|\n",
      "|[nationwide]|          [1]|faq_knowledge_base|senate okays drilling in the gulf of mexico or ...|        Negative|    -0.4588|       0.2107|\n",
      "+------------+-------------+------------------+--------------------------------------------------+----------------+-----------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "    \"brand_name\", \"mention_count\", \"content_type\", \"clean_text\", \"hybrid_sentiment\", \"vader_score\", \"finbert_score\"\n",
    ").show(10, truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea05365-b1ef-4efc-b0be-4574d64dcb3a",
   "metadata": {},
   "source": [
    "# 5. Brand-Specific Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac738a5b-99f0-4ba9-a410-2f8c79bd0d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_sentiment_df = df.select(\n",
    "    explode(arrays_zip(col(\"brand_name\"), col(\"mention_count\"))).alias(\"exploded\"),\n",
    "    col(\"content_type\"),\n",
    "    col(\"vader_score\"),\n",
    "    col(\"sentiment_label\"),\n",
    "    col(\"finbert_label\"),\n",
    "    col(\"finbert_score\"),\n",
    "    col(\"finbert_confidence\"),\n",
    "    col(\"hybrid_sentiment\"),\n",
    "    col(\"date\"),\n",
    "    col(\"month\"),\n",
    "    col(\"year\")\n",
    ").select(\n",
    "    col(\"exploded.brand_name\").alias(\"brand\"),\n",
    "    col(\"exploded.mention_count\").alias(\"mentions\"),\n",
    "    col(\"content_type\"),\n",
    "    col(\"vader_score\"),\n",
    "    col(\"sentiment_label\"),\n",
    "    col(\"finbert_label\"),\n",
    "    col(\"finbert_score\"),\n",
    "    col(\"finbert_confidence\"),\n",
    "    col(\"hybrid_sentiment\"),\n",
    "    col(\"date\"),\n",
    "    col(\"month\"),\n",
    "    col(\"year\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f404ad95-8978-4e85-a74a-bfa872b8a406",
   "metadata": {},
   "source": [
    "### Sentiment by Brand and Content Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34d92d31-765b-4bd8-b847-e1d26edae48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Brand Sentiment Summary for Lloyds:\n",
      "+------+---------------+----------------+--------------+\n",
      "|brand |content_type   |hybrid_sentiment|total_mentions|\n",
      "+------+---------------+----------------+--------------+\n",
      "|lloyds|customer_review|Negative        |16            |\n",
      "|lloyds|customer_review|Positive        |3             |\n",
      "|lloyds|miscellaneous  |Negative        |5             |\n",
      "|lloyds|news_article   |Negative        |25            |\n",
      "|lloyds|news_article   |Neutral         |3             |\n",
      "|lloyds|news_article   |Positive        |13            |\n",
      "|lloyds|user_generated |Positive        |1             |\n",
      "+------+---------------+----------------+--------------+\n",
      "\n",
      "\n",
      "Brand Sentiment Summary for Barclays:\n",
      "+--------+-------------------+----------------+--------------+\n",
      "|brand   |content_type       |hybrid_sentiment|total_mentions|\n",
      "+--------+-------------------+----------------+--------------+\n",
      "|barclays|advertising_content|Positive        |1             |\n",
      "|barclays|blog_post          |Positive        |3             |\n",
      "|barclays|customer_review    |Negative        |4             |\n",
      "|barclays|customer_review    |Positive        |9             |\n",
      "|barclays|faq_knowledge_base |Positive        |2             |\n",
      "|barclays|miscellaneous      |Negative        |1             |\n",
      "|barclays|miscellaneous      |Positive        |1             |\n",
      "|barclays|news_article       |Negative        |12            |\n",
      "|barclays|news_article       |Neutral         |4             |\n",
      "|barclays|news_article       |Positive        |22            |\n",
      "+--------+-------------------+----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filters for the brands of interest\n",
    "brands_of_interest = [\"lloyds\", \"barclays\"]\n",
    "brand_specific_df = brand_sentiment_df.filter(col(\"brand\").isin(brands_of_interest))\n",
    "\n",
    "# Sentiment summaries for each brand\n",
    "for brand in brands_of_interest:\n",
    "    brand_df = brand_specific_df.filter(col(\"brand\") == brand)\n",
    "    \n",
    "    brand_summary = brand_df.groupBy(\n",
    "        \"brand\", \"content_type\", \"hybrid_sentiment\"\n",
    "    ).agg({\"mentions\": \"sum\"}).withColumnRenamed(\"sum(mentions)\", \"total_mentions\")\n",
    "    \n",
    "    print(f\"\\nBrand Sentiment Summary for {brand.capitalize()}:\")\n",
    "    brand_summary.orderBy(\"content_type\", \"hybrid_sentiment\").show(50, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcbda1c-b7e0-4f5d-98bd-8568e7d17e2a",
   "metadata": {},
   "source": [
    "### Sentiment Distribution by Brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d895be79-23a5-4df1-9037-0ddeb2a378de",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_sentiment_counts = brand_summary.groupBy(\"brand\", \"hybrid_sentiment\").agg({\"total_mentions\": \"sum\"}).collect()\n",
    "brands = sorted(set(row[\"brand\"] for row in brand_sentiment_counts))\n",
    "sentiments = [\"Positive\", \"Neutral\", \"Negative\"]\n",
    "data = {sentiment: [0] * len(brands) for sentiment in sentiments}\n",
    "for row in brand_sentiment_counts:\n",
    "    brand_idx = brands.index(row[\"brand\"])\n",
    "    sentiment = row[\"hybrid_sentiment\"]\n",
    "    data[sentiment][brand_idx] = row[\"sum(total_mentions)\"]\n",
    "\n",
    "bar_chart_data = {\n",
    "    \"positive\": data[\"Positive\"],\n",
    "    \"neutral\": data[\"Neutral\"],\n",
    "    \"negative\": data[\"Negative\"],\n",
    "    \"labels\": [\"Barclays\", \"Lloyds\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0df466d5-84f1-4334-a49d-74d801f9ade8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script src=\"https://cdn.jsdelivr.net/npm/chart.js\"></script>\n",
       "<div>\n",
       "    <canvas id=\"barChart\" width=\"600\" height=\"300\"></canvas>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "var barChartData = {\n",
       "    labels: ['Barclays', 'Lloyds'],\n",
       "    datasets: [\n",
       "        {\n",
       "            label: 'Positive',\n",
       "            data: [38],\n",
       "            backgroundColor: 'rgba(75, 192, 192, 0.6)',\n",
       "            borderColor: 'rgba(75, 192, 192, 1)',\n",
       "            borderWidth: 1\n",
       "        },\n",
       "        {\n",
       "            label: 'Neutral',\n",
       "            data: [4],\n",
       "            backgroundColor: 'rgba(153, 162, 235, 0.6)',\n",
       "            borderColor: 'rgba(153, 162, 235, 1)',\n",
       "            borderWidth: 1\n",
       "        },\n",
       "        {\n",
       "            label: 'Negative',\n",
       "            data: [17],\n",
       "            backgroundColor: 'rgba(255, 99, 132, 0.6)',\n",
       "            borderColor: 'rgba(255, 99, 132, 1)',\n",
       "            borderWidth: 1\n",
       "        }\n",
       "    ]\n",
       "};\n",
       "\n",
       "var barCtx = document.getElementById('barChart').getContext('2d');\n",
       "new Chart(barCtx, {\n",
       "    type: 'bar',\n",
       "    data: barChartData,\n",
       "    options: {\n",
       "        scales: {\n",
       "            x: { title: { display: true, text: 'Brand' } },\n",
       "            y: { title: { display: true, text: 'Total Mentions' }, beginAtZero: true }\n",
       "        },\n",
       "        plugins: {\n",
       "            title: { display: true, text: 'Hybrid Sentiment Distribution for Lloyds and Barclays' },\n",
       "            legend: { display: true, position: 'top' }\n",
       "        }\n",
       "    }\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, Javascript\n",
    "\n",
    "html_setup = \"\"\"\n",
    "<script src=\"https://cdn.jsdelivr.net/npm/chart.js\"></script>\n",
    "<div>\n",
    "    <canvas id=\"barChart\" width=\"600\" height=\"300\"></canvas>\n",
    "</div>\n",
    "\"\"\"\n",
    "display(HTML(html_setup))\n",
    "\n",
    "# Pass data to JavaScript\n",
    "bar_chart_js_data = f\"\"\"\n",
    "var barChartData = {{\n",
    "    labels: {bar_chart_data['labels']},\n",
    "    datasets: [\n",
    "        {{\n",
    "            label: 'Positive',\n",
    "            data: {bar_chart_data['positive']},\n",
    "            backgroundColor: 'rgba(75, 192, 192, 0.6)',\n",
    "            borderColor: 'rgba(75, 192, 192, 1)',\n",
    "            borderWidth: 1\n",
    "        }},\n",
    "        {{\n",
    "            label: 'Neutral',\n",
    "            data: {bar_chart_data['neutral']},\n",
    "            backgroundColor: 'rgba(153, 162, 235, 0.6)',\n",
    "            borderColor: 'rgba(153, 162, 235, 1)',\n",
    "            borderWidth: 1\n",
    "        }},\n",
    "        {{\n",
    "            label: 'Negative',\n",
    "            data: {bar_chart_data['negative']},\n",
    "            backgroundColor: 'rgba(255, 99, 132, 0.6)',\n",
    "            borderColor: 'rgba(255, 99, 132, 1)',\n",
    "            borderWidth: 1\n",
    "        }}\n",
    "    ]\n",
    "}};\n",
    "\"\"\"\n",
    "\n",
    "render_bar_chart_js = \"\"\"\n",
    "var barCtx = document.getElementById('barChart').getContext('2d');\n",
    "new Chart(barCtx, {\n",
    "    type: 'bar',\n",
    "    data: barChartData,\n",
    "    options: {\n",
    "        scales: {\n",
    "            x: { title: { display: true, text: 'Brand' } },\n",
    "            y: { title: { display: true, text: 'Total Mentions' }, beginAtZero: true }\n",
    "        },\n",
    "        plugins: {\n",
    "            title: { display: true, text: 'Hybrid Sentiment Distribution for Lloyds and Barclays' },\n",
    "            legend: { display: true, position: 'top' }\n",
    "        }\n",
    "    }\n",
    "});\n",
    "\"\"\"\n",
    "\n",
    "display(Javascript(bar_chart_js_data + render_bar_chart_js))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3676ed-be0c-40bc-a3f9-f440823d71af",
   "metadata": {},
   "source": [
    "### Temporal Sentiment Trends for Lloyds and Barclays (Negative sentiment over time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64c5cb99-8951-4e06-aec6-57f465680f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "temporal_summary = brand_specific_df.groupBy(\n",
    "    \"brand\", \"year\", \"month\", \"hybrid_sentiment\"\n",
    ").agg({\"mentions\": \"sum\"}).withColumnRenamed(\"sum(mentions)\", \"total_mentions\")\n",
    "\n",
    "temporal_data = temporal_summary.filter(col(\"hybrid_sentiment\") == \"Negative\").groupBy(\"brand\", \"year\", \"month\").agg({\"total_mentions\": \"sum\"}).collect()\n",
    "\n",
    "time_labels = sorted(set(f\"{row['year']}-{row['month']:02d}\" for row in temporal_data))\n",
    "lloyds_data = [0] * len(time_labels)\n",
    "barclays_data = [0] * len(time_labels)\n",
    "for row in temporal_data:\n",
    "    time_idx = time_labels.index(f\"{row['year']}-{row['month']:02d}\")\n",
    "    if row['brand'] == \"lloyds\":\n",
    "        lloyds_data[time_idx] = row[\"sum(total_mentions)\"]\n",
    "    elif row['brand'] == \"barclays\":\n",
    "        barclays_data[time_idx] = row[\"sum(total_mentions)\"]\n",
    "\n",
    "line_chart_data = {\n",
    "    \"time_labels\": time_labels,\n",
    "    \"lloyds_data\": lloyds_data,\n",
    "    \"barclays_data\": barclays_data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d261514a-9d80-4b6e-b35f-44f942946e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script src=\"https://cdn.jsdelivr.net/npm/chart.js\"></script>\n",
       "<div>\n",
       "    <canvas id=\"lineChart\" width=\"600\" height=\"300\"></canvas>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "var lineChartData = {\n",
       "    labels: ['2014-03', '2014-07', '2014-12'],\n",
       "    datasets: [\n",
       "        {\n",
       "            label: 'Lloyds Positive Mentions',\n",
       "            data: [3, 16, 27],\n",
       "            borderColor: 'rgba(75, 192, 192, 1)',\n",
       "            backgroundColor: 'rgba(75, 192, 192, 0.2)',\n",
       "            fill: true,\n",
       "            tension: 0.4\n",
       "        },\n",
       "        {\n",
       "            label: 'Barclays Positive Mentions',\n",
       "            data: [3, 4, 10],\n",
       "            borderColor: 'rgba(255, 99, 132, 1)',\n",
       "            backgroundColor: 'rgba(255, 99, 132, 0.2)',\n",
       "            fill: true,\n",
       "            tension: 0.4\n",
       "        }\n",
       "    ]\n",
       "};\n",
       "\n",
       "var lineCtx = document.getElementById('lineChart').getContext('2d');\n",
       "new Chart(lineCtx, {\n",
       "    type: 'line',\n",
       "    data: lineChartData,\n",
       "    options: {\n",
       "        scales: {\n",
       "            x: { title: { display: true, text: 'Year-Month' } },\n",
       "            y: { title: { display: true, text: 'Positive Mentions' }, beginAtZero: true }\n",
       "        },\n",
       "        plugins: {\n",
       "            title: { display: true, text: 'Positive Sentiment Trends for Lloyds and Barclays' },\n",
       "            legend: { display: true, position: 'top' }\n",
       "        }\n",
       "    }\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Include Chart.js and create canvas element\n",
    "html_setup = \"\"\"\n",
    "<script src=\"https://cdn.jsdelivr.net/npm/chart.js\"></script>\n",
    "<div>\n",
    "    <canvas id=\"lineChart\" width=\"600\" height=\"300\"></canvas>\n",
    "</div>\n",
    "\"\"\"\n",
    "display(HTML(html_setup))\n",
    "\n",
    "# Pass line chart data to JavaScript\n",
    "line_chart_js_data = f\"\"\"\n",
    "var lineChartData = {{\n",
    "    labels: {line_chart_data['time_labels']},\n",
    "    datasets: [\n",
    "        {{\n",
    "            label: 'Lloyds Positive Mentions',\n",
    "            data: {line_chart_data['lloyds_data']},\n",
    "            borderColor: 'rgba(75, 192, 192, 1)',\n",
    "            backgroundColor: 'rgba(75, 192, 192, 0.2)',\n",
    "            fill: true,\n",
    "            tension: 0.4\n",
    "        }},\n",
    "        {{\n",
    "            label: 'Barclays Positive Mentions',\n",
    "            data: {line_chart_data['barclays_data']},\n",
    "            borderColor: 'rgba(255, 99, 132, 1)',\n",
    "            backgroundColor: 'rgba(255, 99, 132, 0.2)',\n",
    "            fill: true,\n",
    "            tension: 0.4\n",
    "        }}\n",
    "    ]\n",
    "}};\n",
    "\"\"\"\n",
    "\n",
    "render_line_chart_js = \"\"\"\n",
    "var lineCtx = document.getElementById('lineChart').getContext('2d');\n",
    "new Chart(lineCtx, {\n",
    "    type: 'line',\n",
    "    data: lineChartData,\n",
    "    options: {\n",
    "        scales: {\n",
    "            x: { title: { display: true, text: 'Year-Month' } },\n",
    "            y: { title: { display: true, text: 'Positive Mentions' }, beginAtZero: true }\n",
    "        },\n",
    "        plugins: {\n",
    "            title: { display: true, text: 'Positive Sentiment Trends for Lloyds and Barclays' },\n",
    "            legend: { display: true, position: 'top' }\n",
    "        }\n",
    "    }\n",
    "});\n",
    "\"\"\"\n",
    "\n",
    "display(Javascript(line_chart_js_data + render_line_chart_js))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e042877c-015d-4c81-9b0f-6c15be08b4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
