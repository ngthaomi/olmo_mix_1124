{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c758cf4",
   "metadata": {},
   "source": [
    "# **Brand Sentiment Analysis using OLMo 2 Pre-training Dataset** (OLMo Mix 1124)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdfc934-f454-4547-822e-c400c561776f",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "- [0. Setup](#0-setup)  \n",
    "- [1. Data Loading](#1-data-loading)  \n",
    "- [2. Data Exploration](#2-data-exploration)  \n",
    "- [3. Data Preprocessing](#3-data-preprocessing)  \n",
    "    - [3.1 Data Cleaning](#31-data-cleaning)   \n",
    "    - [3.2 Feature Engineering](#32-feature-engineering)  \n",
    "- [4. Brand Sentiment Analysis](#4-brand-sentiment-analysis)  \n",
    "    - [4.1 Lexicon-Based](#41-lexicon-based)  \n",
    "    - [4.2 Transformer-based](#42-transformer-based)\n",
    "- [5. Visualisations](#5-visualisations)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fcf565-b4d6-4ee3-b89d-c84c6eae06ef",
   "metadata": {},
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a1cc666-f0ae-4f98-aac7-efaf3d8536bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas>=2.2.3 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: numpy>=2.0.2 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (2.0.2)\n",
      "Requirement already satisfied: pyspark>=3.5.0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (3.5.0)\n",
      "Requirement already satisfied: nltk>=3.8 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (3.8.1)\n",
      "Requirement already satisfied: emoji>=2.14.1 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (2.14.1)\n",
      "Requirement already satisfied: transformers>=4.52.4 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (4.52.4)\n",
      "Requirement already satisfied: torch>=2.7.0 in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (2.7.1)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (0.22.1)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (2.7.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (3.10.0)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (3.6.0)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (19.0.0)\n",
      "Requirement already satisfied: fastparquet in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 13)) (2024.11.0)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.12/site-packages (from -r requirements.txt (line 14)) (6.29.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas>=2.2.3->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas>=2.2.3->-r requirements.txt (line 1)) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas>=2.2.3->-r requirements.txt (line 1)) (2025.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.12/site-packages (from pyspark>=3.5.0->-r requirements.txt (line 3)) (0.10.9.7)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.12/site-packages (from nltk>=3.8->-r requirements.txt (line 4)) (8.1.8)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.12/site-packages (from nltk>=3.8->-r requirements.txt (line 4)) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.12/site-packages (from nltk>=3.8->-r requirements.txt (line 4)) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from nltk>=3.8->-r requirements.txt (line 4)) (4.67.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers>=4.52.4->-r requirements.txt (line 6)) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/conda/lib/python3.12/site-packages (from transformers>=4.52.4->-r requirements.txt (line 6)) (0.32.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers>=4.52.4->-r requirements.txt (line 6)) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers>=4.52.4->-r requirements.txt (line 6)) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers>=4.52.4->-r requirements.txt (line 6)) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.12/site-packages (from transformers>=4.52.4->-r requirements.txt (line 6)) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from transformers>=4.52.4->-r requirements.txt (line 6)) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.12/site-packages (from torch>=2.7.0->-r requirements.txt (line 7)) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=2.7.0->-r requirements.txt (line 7)) (75.8.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.12/site-packages (from torch>=2.7.0->-r requirements.txt (line 7)) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=2.7.0->-r requirements.txt (line 7)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=2.7.0->-r requirements.txt (line 7)) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch>=2.7.0->-r requirements.txt (line 7)) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch>=2.7.0->-r requirements.txt (line 7)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch>=2.7.0->-r requirements.txt (line 7)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/conda/lib/python3.12/site-packages (from torch>=2.7.0->-r requirements.txt (line 7)) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /opt/conda/lib/python3.12/site-packages (from torch>=2.7.0->-r requirements.txt (line 7)) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/conda/lib/python3.12/site-packages (from torch>=2.7.0->-r requirements.txt (line 7)) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/conda/lib/python3.12/site-packages (from torch>=2.7.0->-r requirements.txt (line 7)) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/conda/lib/python3.12/site-packages (from torch>=2.7.0->-r requirements.txt (line 7)) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/conda/lib/python3.12/site-packages (from torch>=2.7.0->-r requirements.txt (line 7)) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/conda/lib/python3.12/site-packages (from torch>=2.7.0->-r requirements.txt (line 7)) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/conda/lib/python3.12/site-packages (from torch>=2.7.0->-r requirements.txt (line 7)) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/conda/lib/python3.12/site-packages (from torch>=2.7.0->-r requirements.txt (line 7)) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/conda/lib/python3.12/site-packages (from torch>=2.7.0->-r requirements.txt (line 7)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/conda/lib/python3.12/site-packages (from torch>=2.7.0->-r requirements.txt (line 7)) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /opt/conda/lib/python3.12/site-packages (from torch>=2.7.0->-r requirements.txt (line 7)) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /opt/conda/lib/python3.12/site-packages (from torch>=2.7.0->-r requirements.txt (line 7)) (3.3.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.12/site-packages (from torchvision->-r requirements.txt (line 8)) (11.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 10)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 10)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 10)) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 10)) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 10)) (3.2.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 11)) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 11)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 11)) (0.70.16)\n",
      "Requirement already satisfied: cramjam>=2.3 in /opt/conda/lib/python3.12/site-packages (from fastparquet->-r requirements.txt (line 13)) (2.10.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 14)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 14)) (1.8.12)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/conda/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 14)) (8.32.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 14)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 14)) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 14)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 14)) (1.6.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 14)) (6.1.1)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/conda/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 14)) (26.2.1)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 14)) (6.4.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /opt/conda/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 14)) (5.14.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 11)) (3.11.12)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=4.52.4->-r requirements.txt (line 6)) (1.1.3)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 14)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 14)) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 14)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 14)) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 14)) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /opt/conda/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 14)) (0.6.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 14)) (4.3.6)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=2.2.3->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers>=4.52.4->-r requirements.txt (line 6)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers>=4.52.4->-r requirements.txt (line 6)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers>=4.52.4->-r requirements.txt (line 6)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers>=4.52.4->-r requirements.txt (line 6)) (2024.12.14)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.7.0->-r requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=2.7.0->-r requirements.txt (line 7)) (3.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 11)) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 11)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 11)) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 11)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 11)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 11)) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 11)) (1.18.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/conda/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 14)) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->-r requirements.txt (line 14)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->-r requirements.txt (line 14)) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 14)) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 14)) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/conda/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 14)) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "319f76d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import nltk\n",
    "import zstandard as zstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b13a1817-50a8-4971-ba8b-aa21a5dd4883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, functions as F, types as T\n",
    "from pyspark.sql.functions import col, udf, pandas_udf, PandasUDFType, arrays_zip, array_contains, substring, length, explode, first, avg, when, monotonically_increasing_id\n",
    "from pyspark.sql.functions import to_date, dayofmonth, month, year\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType, FloatType, BooleanType, ArrayType, StructType, StructField\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from functools import reduce\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from collections import defaultdict\n",
    "from emoji import demojize\n",
    "from urllib.parse import urlparse\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324cefc4-be05-4082-81ae-80cbd6ec1f6c",
   "metadata": {},
   "source": [
    "# 1. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feea5af6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/06 00:06:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 33610)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/socketserver.py\", line 318, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.12/socketserver.py\", line 349, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.12/socketserver.py\", line 362, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/opt/conda/lib/python3.12/socketserver.py\", line 761, in __init__\n",
      "    self.handle()\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "                           ^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Spark initialisation\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Olmo Mix 1124 Sentiment Analysis\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"16g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"4\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "765309ab-9d30-4039-96dd-0672608f4e34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Decompressses files\n",
    "input_dir = \"./data\"  # folder containing .jsonl.zstd files\n",
    "output_dir = \"./data/temp_jsonl\"  # temporary location for decompressed files\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "decompressed_files = []\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".jsonl.zstd\"):\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        output_path = os.path.join(output_dir, filename.replace(\".zstd\", \"\"))\n",
    "        decompressed_files.append(output_path)\n",
    "\n",
    "        with open(input_path, 'rb') as compressed:\n",
    "            dctx = zstd.ZstdDecompressor()\n",
    "            with open(output_path, 'wb') as out:\n",
    "                dctx.copy_stream(compressed, out)\n",
    "\n",
    "# Aligns metadata schema \n",
    "metadata_schema = T.StructType([\n",
    "    T.StructField(\"Content-Length\", T.StringType(), True),\n",
    "    T.StructField(\"Content-Type\", T.StringType(), True),\n",
    "    T.StructField(\"WARC-Block-Digest\", T.StringType(), True),\n",
    "    T.StructField(\"WARC-Concurrent-To\", T.StringType(), True),\n",
    "    T.StructField(\"WARC-Date\", T.StringType(), True),\n",
    "    T.StructField(\"WARC-IP-Address\", T.StringType(), True),\n",
    "    T.StructField(\"WARC-Payload-Digest\", T.StringType(), True),\n",
    "    T.StructField(\"WARC-Record-ID\", T.StringType(), True),\n",
    "    T.StructField(\"WARC-Target-URI\", T.StringType(), True),\n",
    "    T.StructField(\"WARC-Truncated\", T.StringType(), True),\n",
    "    T.StructField(\"WARC-Type\", T.StringType(), True),\n",
    "    T.StructField(\"WARC-Warcinfo-ID\", T.StringType(), True),\n",
    "    T.StructField(\"WARC-Identified-Payload-Type\", T.StringType(), True),\n",
    "])\n",
    "\n",
    "# Pad metadata fields to align schemas\n",
    "def pad_metadata_column(df):\n",
    "    existing_fields = df.select(\"metadata.*\").columns\n",
    "\n",
    "    new_metadata_cols = []\n",
    "    for field in metadata_schema:\n",
    "        if field.name in existing_fields:\n",
    "            new_metadata_cols.append(F.col(\"metadata\").getField(field.name).alias(field.name))\n",
    "        else:\n",
    "            new_metadata_cols.append(F.lit(None).cast(field.dataType).alias(field.name))\n",
    "\n",
    "    return df.withColumn(\"metadata\", F.struct(new_metadata_cols))\n",
    "\n",
    "df_list = []\n",
    "for file_path in decompressed_files:\n",
    "    df = spark.read.json(file_path)\n",
    "    if \"metadata\" in df.columns:\n",
    "        df = pad_metadata_column(df)\n",
    "    else:\n",
    "        # if metadata column missing entirely, add it as null struct\n",
    "        df = df.withColumn(\"metadata\", F.lit(None).cast(metadata_schema))\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2775473b-a9e3-412f-95be-90c871a5962d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+---------------------------------------------------------------+-------------------------------+--------------------+-------------------+--------------------+--------------------+--------------------+\n",
      "|bff_contained_ngram_count_before_dedupe|fasttext_openhermes_reddit_eli5_vs_rw_v2_bigram_200k_train_prob|language_id_whole_page_fasttext|            metadata|previous_word_count|                text|                 url|            warcinfo|\n",
      "+---------------------------------------+---------------------------------------------------------------+-------------------------------+--------------------+-------------------+--------------------+--------------------+--------------------+\n",
      "|                                     25|                                           0.028186440467834473|           {0.9871476292610168}|{90145, applicati...|               1052|Lavender Scare: U...|http://abcnews.go...|robots: classic\\r...|\n",
      "|                                    317|                                           0.028110027313232422|           {0.9051697850227356}|{3069, applicatio...|                309|TY - JOUR T1 - AS...|http://archpedi.j...|robots: classic\\r...|\n",
      "|                                     34|                                            0.04570215940475464|           {0.9768716096878052}|{45887, applicati...|                807|Mentor vs. pupil ...|http://articles.c...|robots: classic\\r...|\n",
      "|                                    130|                                           0.021046340465545654|           {0.9788495898246764}|{44841, applicati...|                854|Judge refuses to ...|http://articles.m...|robots: classic\\r...|\n",
      "|                                     49|                                            0.09183675050735474|           {0.9740573763847352}|{34772, applicati...|               2334|Join 3,380 reader...|http://ask.metafi...|robots: classic\\r...|\n",
      "|                                    198|                                           0.041249215602874756|           {0.9445648789405824}|{232385, applicat...|               5416|Slashdot: News fo...|http://beta.slash...|robots: classic\\r...|\n",
      "|                                      0|                                            0.02820640802383423|           {0.9817960262298584}|{90441, applicati...|               1285|Arsenal V Barcelo...|http://bleacherre...|robots: classic\\r...|\n",
      "|                                      0|                                             0.6333076357841492|           {0.9432296752929688}|{76224, applicati...|                150|The Terrible Towe...|http://bleacherre...|robots: classic\\r...|\n",
      "|                                    320|                                           0.020612716674804688|            {0.909352958202362}|{9700, applicatio...|                870|Bleacher Report -...|http://bleacherre...|robots: classic\\r...|\n",
      "|                                      0|                                           0.019466042518615723|            {0.990231990814209}|{7727, applicatio...|                677|Great Horned Owl\\...|http://blog.humph...|robots: classic\\r...|\n",
      "|                                    652|                                           0.040959954261779785|           {0.9657678008079528}|{177364, applicat...|               7783|Â« The NCLB Parado...|http://blogs.edwe...|robots: classic\\r...|\n",
      "|                                      1|                                             0.1991196870803833|            {0.958015501499176}|{43406, applicati...|                110|Search for conten...|http://boards.anc...|robots: classic\\r...|\n",
      "|                                      0|                                           0.026132941246032715|           {0.8747656941413879}|{74574, applicati...|                 68|What is the purpo...|http://community....|robots: classic\\r...|\n",
      "|                                      6|                                             0.3811795115470886|           {0.9682596921920776}|{96016, applicati...|               1550|\\n\\nSnyder Says R...|http://cowboyszon...|robots: classic\\r...|\n",
      "|                                     17|                                              0.241152822971344|            {0.709584653377533}|{5329, applicatio...|                132|\\n\\nCreating a Sc...|http://docs.oracl...|robots: classic\\r...|\n",
      "|                                      9|                                            0.30792516469955444|           {0.7978588938713074}|{5945, applicatio...|                222|\\n\\nProcedureTo R...|http://docs.oracl...|robots: classic\\r...|\n",
      "|                                     74|                                             0.0871802568435669|           {0.9265103340148926}|{47381, applicati...|                244|Where has all the...|http://edexcellen...|robots: classic\\r...|\n",
      "|                                     44|                                             0.2194066047668457|           {0.9607746601104736}|{33921, applicati...|                311|From Wikipedia, t...|http://en.wikiped...|robots: classic\\r...|\n",
      "|                                    166|                                           0.021839499473571777|           {0.9173826575279236}|{56278, applicati...|               1040|Calotropis procer...|http://en.wikiped...|robots: classic\\r...|\n",
      "|                                     87|                                            0.05404263734817505|            {0.968736469745636}|{59933, applicati...|               1439|Ariadne (empress)...|http://en.wikiped...|robots: classic\\r...|\n",
      "+---------------------------------------+---------------------------------------------------------------+-------------------------------+--------------------+-------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combining all dataframes into a combined dataframe\n",
    "df = reduce(lambda a, b: a.unionByName(b, allowMissingColumns=True), df_list)\n",
    "df.show()\n",
    "\n",
    "# Can convert to Parquet format\n",
    "# df.write.mode(\"overwrite\").parquet(\"data/combined_data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521c4bff-f6fe-40b6-a372-7d12fadbd8aa",
   "metadata": {},
   "source": [
    "| Column Name | Description |\n",
    "|-------------|-------------|\n",
    "| `bff_contained_ngram_count_before_dedupe` | Number of known n-grams from the BFF (Base Filtered Fragments) list that were found before deduplication. Higher counts imply overlap with previously seen content, used in deduplication. |\n",
    "| `fasttext_openhermes_reddit_eli5_vs_rw_v2_bigram_200k_train_prob` | FastText model output indicating the likelihood this text resembles a specific user-generated corpus (computed based on bigram training probabilities). |\n",
    "| `language_id_whole_page_fasttext` | Probability or confidence that the whole page is in English. |\n",
    "| `metadata` | Structured metadata `{doc_id, source_tag, timestamp, ...}`. |\n",
    "| `previous_word_count` | Word count of this document or segment before it was deduplicated. |\n",
    "| `text` | The main text body extracted from the document.|\n",
    "| `url` | The original URL source of the content. Can be used for classifying content type (e.g., forums, news articles, advertising, social media, etc.). |\n",
    "| `warcinfo` | Extracted metadata from the WARC.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90dcc1f3-fd3b-4f16-a7e2-d65d907855ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- bff_contained_ngram_count_before_dedupe: long (nullable = true)\n",
      " |-- fasttext_openhermes_reddit_eli5_vs_rw_v2_bigram_200k_train_prob: double (nullable = true)\n",
      " |-- language_id_whole_page_fasttext: struct (nullable = true)\n",
      " |    |-- en: double (nullable = true)\n",
      " |-- metadata: struct (nullable = false)\n",
      " |    |-- Content-Length: string (nullable = true)\n",
      " |    |-- Content-Type: string (nullable = true)\n",
      " |    |-- WARC-Block-Digest: string (nullable = true)\n",
      " |    |-- WARC-Concurrent-To: string (nullable = true)\n",
      " |    |-- WARC-Date: string (nullable = true)\n",
      " |    |-- WARC-IP-Address: string (nullable = true)\n",
      " |    |-- WARC-Payload-Digest: string (nullable = true)\n",
      " |    |-- WARC-Record-ID: string (nullable = true)\n",
      " |    |-- WARC-Target-URI: string (nullable = true)\n",
      " |    |-- WARC-Truncated: string (nullable = true)\n",
      " |    |-- WARC-Type: string (nullable = true)\n",
      " |    |-- WARC-Warcinfo-ID: string (nullable = true)\n",
      " |    |-- WARC-Identified-Payload-Type: string (nullable = true)\n",
      " |-- previous_word_count: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- warcinfo: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c74eab39-11da-4d15-bc84-4cfbbd31575c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:======================================================>  (23 + 1) / 24]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 392833\n",
      "Number of columns: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "num_rows = df.count()\n",
    "num_cols = len(df.columns)\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(f\"Number of columns: {num_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372e042e-cd06-4d2b-be2a-02f56a1cf9f5",
   "metadata": {},
   "source": [
    "# 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bcd526-9a24-47f9-adb0-ca7339659808",
   "metadata": {},
   "source": [
    "## 3.1 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e38a9ee-62bf-437e-92a9-1382d7dcb082",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter for non-null/non-empty text\n",
    "df = df.filter(col(\"text\").isNotNull() & (col(\"text\") != \"\"))\n",
    "\n",
    "# Rename for usability\n",
    "df = (df\n",
    "      .withColumnRenamed(\"fasttext_openhermes_reddit_eli5_vs_rw_v2_bigram_200k_train_prob\", \"user_gen_prob\")\n",
    "      .withColumnRenamed(\"language_id_whole_page_fasttext\", \"lang_en_prob\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96ca88ee-f19e-46d5-950a-3d3cabf82bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only high-confidence English content\n",
    "df = df.filter(col(\"lang_en_prob.en\") >= 0.95)\n",
    "\n",
    "# Filter low-signal/high-duplicate content\n",
    "df = df.filter(col(\"bff_contained_ngram_count_before_dedupe\") < 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b94418d6-eeff-401e-a2aa-4ed193cc713c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(\"bff_contained_ngram_count_before_dedupe\", \"warcinfo\", \"lang_en_prob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e31b1ea-3f36-4688-ba19-8a68cbba5531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_count\n",
    "df = df.withColumnRenamed(\"previous_word_count\", \"word_count\")\n",
    "df = df.filter(col(\"word_count\") >= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30f31c3e-442f-4902-be10-b486fd817bf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tokenise text\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    text = re.sub(r'[\\n\\r]', ' ', text)     # Remove newlines and carriage returns\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())     # Remove punctuation and lowercase\n",
    "    text = re.sub(r'\\d+', '', text)   # Remove digits\n",
    "    text = re.sub(r'\\s+', ' ', text).strip() # Normalize whitespace\n",
    "    text = demojize(text)  # Convert emojis to text (e.g., ðŸ˜Š â†’ :smiling_face:)\n",
    "    text = re.sub(r'[^\\w\\s:]', '', text.lower())  # Preserve emoji tokens\n",
    "    return text\n",
    "\n",
    "def nltk_tokenize(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return []\n",
    "    return word_tokenize(text)\n",
    "\n",
    "clean_udf = udf(clean_text, StringType())\n",
    "tokenize_udf = udf(nltk_tokenize, ArrayType(StringType()))\n",
    "\n",
    "# Clean text\n",
    "df = df.withColumn(\"clean_text\", clean_udf(col(\"text\")))\n",
    "\n",
    "# Tokenise text\n",
    "df = df.withColumn(\"tokens\", tokenize_udf(col(\"clean_text\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2aed97c-9f9d-44d0-8bc7-e251c46bca44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+\n",
      "|       user_gen_prob|            metadata|word_count|                text|                 url|          clean_text|              tokens|\n",
      "+--------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+\n",
      "|0.028186440467834473|{90145, applicati...|      1052|Lavender Scare: U...|http://abcnews.go...|lavender scare us...|[lavender, scare,...|\n",
      "| 0.04570215940475464|{45887, applicati...|       807|Mentor vs. pupil ...|http://articles.c...|mentor vs pupil i...|[mentor, vs, pupi...|\n",
      "|0.021046340465545654|{44841, applicati...|       854|Judge refuses to ...|http://articles.m...|judge refuses to ...|[judge, refuses, ...|\n",
      "| 0.09183675050735474|{34772, applicati...|      2334|Join 3,380 reader...|http://ask.metafi...|join readers in h...|[join, readers, i...|\n",
      "| 0.02820640802383423|{90441, applicati...|      1285|Arsenal V Barcelo...|http://bleacherre...|arsenal v barcelo...|[arsenal, v, barc...|\n",
      "|0.019466042518615723|{7727, applicatio...|       677|Great Horned Owl\\...|http://blog.humph...|great horned owl ...|[great, horned, o...|\n",
      "|0.040959954261779785|{177364, applicat...|      7783|Â« The NCLB Parado...|http://blogs.edwe...|the nclb paradox ...|[the, nclb, parad...|\n",
      "|  0.1991196870803833|{43406, applicati...|       110|Search for conten...|http://boards.anc...|search for conten...|[search, for, con...|\n",
      "|  0.3811795115470886|{96016, applicati...|      1550|\\n\\nSnyder Says R...|http://cowboyszon...|snyder says redsk...|[snyder, says, re...|\n",
      "|  0.2194066047668457|{33921, applicati...|       311|From Wikipedia, t...|http://en.wikiped...|from wikipedia th...|[from, wikipedia,...|\n",
      "| 0.05404263734817505|{59933, applicati...|      1439|Ariadne (empress)...|http://en.wikiped...|ariadne empress f...|[ariadne, empress...|\n",
      "| 0.05462205410003662|{137583, applicat...|      3525|From Wikipedia, t...|http://en.wikiped...|from wikipedia th...|[from, wikipedia,...|\n",
      "| 0.06115531921386719|{59145, applicati...|       812|From Wikipedia, t...|http://en.wikiped...|from wikipedia th...|[from, wikipedia,...|\n",
      "|  0.1461053490638733|{35752, applicati...|       434|From Wikipedia, t...|http://en.wikiped...|from wikipedia th...|[from, wikipedia,...|\n",
      "| 0.04330480098724365|{69800, applicati...|       886|\\n\\nPHOTO:Â Renya,...|http://fusion.net...|photo renya cast ...|[photo, renya, ca...|\n",
      "|0.026266515254974365|{71697, applicati...|       222|Meet April Kepner...|http://gawker.com...|meet april kepner...|[meet, april, kep...|\n",
      "|  0.1078881025314331|{70869, applicati...|       104|PS3 Eye Hacked in...|http://gizmodo.co...|ps eye hacked int...|[ps, eye, hacked,...|\n",
      "|  0.8801420331001282|{67258, applicati...|        66|Recently, Dell's ...|http://gizmodo.co...|recently dells be...|[recently, dells,...|\n",
      "| 0.01957935094833374|{74269, applicati...|       153|Dell Buys Ross Pe...|http://gizmodo.co...|dell buys ross pe...|[dell, buys, ross...|\n",
      "|0.029358267784118652|{71046, applicati...|       240|Stackable City Of...|http://io9.com/34...|stackable city of...|[stackable, city,...|\n",
      "+--------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "013920cf-ad63-45d8-8f70-e24be965d410",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:=====================================================>  (23 + 1) / 24]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 182600\n",
      "Number of columns: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "num_rows = df.count()\n",
    "num_cols = len(df.columns)\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(f\"Number of columns: {num_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61eb2af-c74d-452f-83eb-281953a328d8",
   "metadata": {},
   "source": [
    "## 3.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d96e9c2-6acb-4257-b8cd-d6eb33f309f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UK banks\n",
    "BRANDS = [\"barclays\", \"lloyds\", \"natwest\", \"hsbc\", \"monzo\", \"revolut\", \"tsb\", \"santander\", \"starling\", \"nationwide\"]\n",
    "\n",
    "# Banking-related context terms to confirm brand relevance\n",
    "BANKING_CONTEXT = [\n",
    "    \"finance\", \"financial\", \"bank\", \"banking\", \"account\", \"savings\", \"current\", \"mortgage\", \"loan\", \"credit\", \"debit\", \"card\",\n",
    "    \"app\", \"mobile\", \"online\", \"branch\", \"atm\", \"transfer\", \"fees\", \"overdraft\", \"service\", \"support\"\n",
    "]\n",
    "\n",
    "# Negative context terms to exclude false positives\n",
    "NEGATIVE_CONTEXT = {\n",
    "    \"nationwide\": [\"global\", \"worldwide\", \"across the nation\", \"nationwide coverage\"],\n",
    "    \"revolut\": [\"revolution\", \"revolutionary\", \"national revolution\"],\n",
    "    \"barclays\": [\"barclays center\", \"barclays arena\"],\n",
    "    \"lloyds\": [\"lloyds of london\"],\n",
    "    \"natwest\": [],  \n",
    "    \"hsbc\": [],    \n",
    "    \"monzo\": [],   \n",
    "    \"tsb\": [],    \n",
    "    \"santander\": [], \n",
    "    \"starling\": [\"starling bird\", \"starlings\"],\n",
    "    \"nationwide\": [\"nationwide insurance\"]  # excludes US insurance company\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc51365c-7097-42de-9273-6c5e4ae472b5",
   "metadata": {},
   "source": [
    "### Extraction of Brand-related Content: *brand_name* and *mention_count*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d3b294e-9c89-49ac-84b9-f555b80b78e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+------------+-------------+\n",
      "|       user_gen_prob|            metadata|word_count|                text|                 url|          clean_text|              tokens|  brand_name|mention_count|\n",
      "+--------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+------------+-------------+\n",
      "| 0.12067514657974243|{281399, applicat...|      6572|Forgot your passw...|http://slashdot.o...|forgot your passw...|[forgot, your, pa...|[nationwide]|          [1]|\n",
      "|0.024826467037200928|{157993, applicat...|       929|Golf Digest edito...|http://www.golfdi...|golf digest edito...|[golf, digest, ed...|      [hsbc]|          [1]|\n",
      "| 0.12538021802902222|{123284, applicat...|      5279|Friday, June 18, ...|http://hotinterne...|friday june write...|[friday, june, wr...|      [hsbc]|          [1]|\n",
      "| 0.02234506607055664|{79753, applicati...|       910|Get the Feds Out ...|http://www.nation...|get the feds out ...|[get, the, feds, ...|[nationwide]|          [1]|\n",
      "| 0.10335409641265869|{50377, applicati...|      1479|1953 Pennsylvania...|http://en.wikiped...|pennsylvania rail...|[pennsylvania, ra...|[nationwide]|          [1]|\n",
      "|  0.1680733561515808|{151572, applicat...|       666|OpinionTop of the...|http://www.latime...|opiniontop of the...|[opiniontop, of, ...|[nationwide]|          [1]|\n",
      "| 0.06693309545516968|{86959, applicati...|      2931|Call for Book Rev...|http://www.popmat...|call for book rev...|[call, for, book,...|[nationwide]|          [1]|\n",
      "| 0.04973882436752319|{47068, applicati...|       523|The Skeptics\\n\\nO...|http://nationalin...|the skeptics of m...|[the, skeptics, o...|[nationwide]|          [1]|\n",
      "|0.025235652923583984|{65069, applicati...|       458|Zille links up wi...|http://www.econom...|zille links up wi...|[zille, links, up...|[nationwide]|          [1]|\n",
      "|0.031493186950683594|{48560, applicati...|       533|Kurt Busch hoping...|http://www.utsand...|kurt busch hoping...|[kurt, busch, hop...|[nationwide]|          [1]|\n",
      "|0.040141403675079346|{47817, applicati...|       213|LaHood calls for ...|http://www.wbez.o...|lahood calls for ...|[lahood, calls, f...|[nationwide]|          [1]|\n",
      "|0.018776357173919678|{65665, applicati...|       959|Credit Crunch | T...|http://www.thenat...|credit crunch the...|[credit, crunch, ...|[nationwide]|          [1]|\n",
      "| 0.04572635889053345|{44950, applicati...|       836|YOU ARE HERE: LAT...|http://articles.l...|you are here lat ...|[you, are, here, ...|  [barclays]|          [1]|\n",
      "| 0.08526510000228882|{117507, applicat...|       399|Howdy, Stranger!\\...|http://forums.edm...|howdy stranger ho...|[howdy, stranger,...|       [tsb]|          [1]|\n",
      "|0.028031647205352783|{83857, applicati...|       319|The only thing an...|http://online.wsj...|the only thing an...|[the, only, thing...|  [barclays]|          [1]|\n",
      "| 0.18311870098114014|{99076, applicati...|      1655|Forgot your passw...|http://slashdot.o...|forgot your passw...|[forgot, your, pa...|  [starling]|          [2]|\n",
      "| 0.21708494424819946|{89706, applicati...|      1727|A brief history o...|http://www.scmp.c...|a brief history o...|[a, brief, histor...|      [hsbc]|          [1]|\n",
      "| 0.02918154001235962|{108441, applicat...|      1872|\\n\\n\\nOn one side...|http://online.wsj...|on one side are t...|[on, one, side, a...|[nationwide]|          [1]|\n",
      "|0.022928059101104736|{188983, applicat...|       629|Does the GOP Need...|http://www.bet.co...|does the gop need...|[does, the, gop, ...|[nationwide]|          [1]|\n",
      "| 0.10605061054229736|{111138, applicat...|       475|I was cheated out...|http://www.thegua...|i was cheated out...|[i, was, cheated,...|  [barclays]|          [8]|\n",
      "+--------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "def extract_brands_and_counts(text):\n",
    "    if not isinstance(text, str):\n",
    "        return [], []\n",
    "    text_lower = text.lower()\n",
    "    tokens = word_tokenize(text_lower)\n",
    "    \n",
    "    brands_found = []\n",
    "    counts = []\n",
    "    \n",
    "    for brand in BRANDS:\n",
    "        brand_count = 0\n",
    "        \n",
    "        # Check for brand in tokens with word boundaries\n",
    "        brand_pattern = r'\\b' + re.escape(brand) + r'\\b'\n",
    "        matches = re.findall(brand_pattern, text_lower)\n",
    "        brand_count += len(matches)\n",
    "        \n",
    "        # Validating with banking context (at least 1 banking term nearby)\n",
    "        has_banking_context = False\n",
    "        for context in BANKING_CONTEXT:\n",
    "            if context in text_lower:\n",
    "                has_banking_context = True\n",
    "                break\n",
    "        \n",
    "        # Check for negative context to exclude false positives\n",
    "        has_negative_context = False\n",
    "        for negative_term in NEGATIVE_CONTEXT.get(brand, []):\n",
    "            if negative_term in text_lower:\n",
    "                has_negative_context = True\n",
    "                break\n",
    "        \n",
    "        # Only include brand if it has banking context and no negative context\n",
    "        if brand_count > 0 and has_banking_context and not has_negative_context:\n",
    "            brands_found.append(brand)\n",
    "            counts.append(brand_count)\n",
    "    \n",
    "    return brands_found, counts\n",
    "\n",
    "@udf(ArrayType(StringType()))\n",
    "def extract_brands(text):\n",
    "    brands, _ = extract_brands_and_counts(text)\n",
    "    return brands\n",
    "\n",
    "@udf(ArrayType(IntegerType()))\n",
    "def extract_mention_counts(text):\n",
    "    _, counts = extract_brands_and_counts(text)\n",
    "    return counts\n",
    "\n",
    "df = df.withColumn(\"brand_name\", extract_brands(col(\"clean_text\")))\n",
    "df = df.withColumn(\"mention_count\", extract_mention_counts(col(\"clean_text\")))\n",
    "\n",
    "# Filter rows with at least 1 valid brand mention\n",
    "df = df.filter(col(\"brand_name\").isNotNull() & (col(\"brand_name\").getItem(0).isNotNull()))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a936d1f-4f0b-4cf2-ab62-954072ff8ee7",
   "metadata": {},
   "source": [
    "### *url_domain*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f95a49c7-494f-4ccc-a6a8-ebbcdaa0ea04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url_domain\n",
    "@udf(StringType())\n",
    "def extract_domain(url):\n",
    "    if not isinstance(url, str):\n",
    "        return \"\"\n",
    "    parsed = urlparse(url)\n",
    "    return parsed.netloc or \"\"\n",
    "\n",
    "df = df.withColumn(\"url_domain\", extract_domain(col(\"url\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fc79bb-4756-4944-a900-488ed54c2e3f",
   "metadata": {},
   "source": [
    "### Classification of Brand-related Content: *content_type*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da944af8-ed57-496b-add8-1116f299352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_content(url, prob, text, content_type):\n",
    "    if not isinstance(url, str):\n",
    "        url = \"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = \"\"\n",
    "    if not isinstance(content_type, str):\n",
    "        content_type = \"\"\n",
    "    \n",
    "    url = url.lower()\n",
    "    text = text.lower()\n",
    "    content_type = content_type.lower()\n",
    "    prob = prob if prob is not None else 0.0\n",
    "    \n",
    "    # Social media: High FastText score or social platforms\n",
    "    social_media_domains = [\n",
    "        \"reddit\", \"twitter\", \"x.com\", \"facebook\", \"linkedin\", \"instagram\",\n",
    "        \"tiktok\", \"pinterest\", \"forum\", \"discuss\", \"community\"\n",
    "    ]\n",
    "    if prob >= 0.5 or any(domain in url for domain in social_media_domains):\n",
    "        return \"user_generated\"\n",
    "    \n",
    "    # News article: Reputable news sources\n",
    "    news_domains = [\n",
    "        \"bbc\", \"guardian\", \"telegraph\", \"ft.com\", \"reuters\", \"bloomberg\",\n",
    "        \"cnn\", \"nytimes\", \"independent\", \"dailymail\", \"sky.com\", \"news\"\n",
    "    ]\n",
    "    if any(domain in url for domain in news_domains) or \"news\" in text:\n",
    "        return \"news_article\"\n",
    "    \n",
    "    # Customer review: Review platforms or review-related keywords\n",
    "    review_domains = [\"trustpilot\", \"feefo\", \"reviews\", \"yelp\", \"google.com/reviews\"]\n",
    "    review_keywords = [\"review\", \"rated\", \"rating\", \"customer feedback\", \"complaint\", \"testimonial\"]\n",
    "    if any(domain in url for domain in review_domains) or any(keyword in text for keyword in review_keywords):\n",
    "        return \"customer_review\"\n",
    "    \n",
    "    # Blog post: Blog platforms or keywords\n",
    "    blog_domains = [\"medium\", \"wordpress\", \"blogger\", \"tumblr\", \"substack\"]\n",
    "    blog_keywords = [\"blog\", \"post\", \"article by\", \"opinion piece\"]\n",
    "    if any(domain in url for domain in blog_domains) or any(keyword in text for keyword in blog_keywords):\n",
    "        return \"blog_post\"\n",
    "    \n",
    "    # Regulatory document: Official or compliance-related sources\n",
    "    regulatory_domains = [\"fca.org.uk\", \"bankofengland\", \"gov.uk\", \"regulations\", \"compliance\"]\n",
    "    if any(domain in url for domain in regulatory_domains) or content_type == \"application/pdf\":\n",
    "        return \"regulatory_document\"\n",
    "    \n",
    "    # Advertising content: Promotional keywords\n",
    "    advertising_keywords = [\"ads\", \"campaign\", \"promo\", \"sponsor\", \"advert\", \"promotion\"]\n",
    "    if any(term in url for term in advertising_keywords) or any(term in text for term in advertising_keywords):\n",
    "        return \"advertising_content\"\n",
    "    \n",
    "    # Owned media: Brand or institutional domains\n",
    "    owned_media_domains = [\n",
    "        \"gov.uk\", \"ac.uk\", \"co.uk\", \"barclays\", \"lloyds\", \"natwest\", \"hsbc\",\n",
    "        \"monzo\", \"revolut\", \"tsb\", \"santander\", \"starling\", \"nationwide\"\n",
    "    ]\n",
    "    if any(domain in url for domain in owned_media_domains):\n",
    "        return \"owned_media\"\n",
    "    \n",
    "    # Forum post: Specific forum platforms\n",
    "    forum_domains = [\"moneysavingexpert\", \"thestudentroom\", \"forums\", \"discussion\"]\n",
    "    if any(domain in url for domain in forum_domains) and prob >= 0.3:\n",
    "        return \"forum_post\"\n",
    "    \n",
    "    # FAQ/Knowledge base: Support or informational pages\n",
    "    faq_keywords = [\"faq\", \"help\", \"support\", \"knowledge base\", \"how to\", \"guide\"]\n",
    "    if any(keyword in url for keyword in faq_keywords) or any(keyword in text for keyword in faq_keywords):\n",
    "        return \"faq_knowledge_base\"\n",
    "    \n",
    "    # Default: Other\n",
    "    return \"miscellaneous\"\n",
    "\n",
    "content_type_udf = udf(classify_content, StringType())\n",
    "df = df.withColumn(\"content_type\", content_type_udf(\n",
    "    col(\"url\"),\n",
    "    col(\"user_gen_prob\"),\n",
    "    col(\"clean_text\"),\n",
    "    col(\"metadata.Content-Type\")\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80381bd0-c90e-4d04-a561-f606a6f94e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+------------+-------------+--------------------+------------------+\n",
      "|       user_gen_prob|            metadata|word_count|                text|                 url|          clean_text|              tokens|  brand_name|mention_count|          url_domain|      content_type|\n",
      "+--------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+------------+-------------+--------------------+------------------+\n",
      "| 0.12067514657974243|{281399, applicat...|      6572|Forgot your passw...|http://slashdot.o...|forgot your passw...|[forgot, your, pa...|[nationwide]|          [1]|        slashdot.org|      news_article|\n",
      "|0.024826467037200928|{157993, applicat...|       929|Golf Digest edito...|http://www.golfdi...|golf digest edito...|[golf, digest, ed...|      [hsbc]|          [1]|  www.golfdigest.com|      news_article|\n",
      "| 0.12538021802902222|{123284, applicat...|      5279|Friday, June 18, ...|http://hotinterne...|friday june write...|[friday, june, wr...|      [hsbc]|          [1]|hotinternet.blogs...|      news_article|\n",
      "| 0.02234506607055664|{79753, applicati...|       910|Get the Feds Out ...|http://www.nation...|get the feds out ...|[get, the, feds, ...|[nationwide]|          [1]|www.nationalrevie...|      news_article|\n",
      "| 0.10335409641265869|{50377, applicati...|      1479|1953 Pennsylvania...|http://en.wikiped...|pennsylvania rail...|[pennsylvania, ra...|[nationwide]|          [1]|    en.wikipedia.org|      news_article|\n",
      "|  0.1680733561515808|{151572, applicat...|       666|OpinionTop of the...|http://www.latime...|opiniontop of the...|[opiniontop, of, ...|[nationwide]|          [1]|     www.latimes.com|     miscellaneous|\n",
      "| 0.06693309545516968|{86959, applicati...|      2931|Call for Book Rev...|http://www.popmat...|call for book rev...|[call, for, book,...|[nationwide]|          [1]|  www.popmatters.com|      news_article|\n",
      "| 0.04973882436752319|{47068, applicati...|       523|The Skeptics\\n\\nO...|http://nationalin...|the skeptics of m...|[the, skeptics, o...|[nationwide]|          [1]|nationalinterest.org|faq_knowledge_base|\n",
      "|0.025235652923583984|{65069, applicati...|       458|Zille links up wi...|http://www.econom...|zille links up wi...|[zille, links, up...|[nationwide]|          [1]|   www.economist.com|         blog_post|\n",
      "|0.031493186950683594|{48560, applicati...|       533|Kurt Busch hoping...|http://www.utsand...|kurt busch hoping...|[kurt, busch, hop...|[nationwide]|          [1]|  www.utsandiego.com|      news_article|\n",
      "|0.040141403675079346|{47817, applicati...|       213|LaHood calls for ...|http://www.wbez.o...|lahood calls for ...|[lahood, calls, f...|[nationwide]|          [1]|        www.wbez.org|     miscellaneous|\n",
      "|0.018776357173919678|{65665, applicati...|       959|Credit Crunch | T...|http://www.thenat...|credit crunch the...|[credit, crunch, ...|[nationwide]|          [1]|   www.thenation.com|      news_article|\n",
      "| 0.04572635889053345|{44950, applicati...|       836|YOU ARE HERE: LAT...|http://articles.l...|you are here lat ...|[you, are, here, ...|  [barclays]|          [1]|articles.latimes.com|   customer_review|\n",
      "| 0.08526510000228882|{117507, applicat...|       399|Howdy, Stranger!\\...|http://forums.edm...|howdy stranger ho...|[howdy, stranger,...|       [tsb]|          [1]|  forums.edmunds.com|    user_generated|\n",
      "|0.028031647205352783|{83857, applicati...|       319|The only thing an...|http://online.wsj...|the only thing an...|[the, only, thing...|  [barclays]|          [1]|      online.wsj.com|      news_article|\n",
      "| 0.18311870098114014|{99076, applicati...|      1655|Forgot your passw...|http://slashdot.o...|forgot your passw...|[forgot, your, pa...|  [starling]|          [2]|        slashdot.org|   customer_review|\n",
      "| 0.21708494424819946|{89706, applicati...|      1727|A brief history o...|http://www.scmp.c...|a brief history o...|[a, brief, histor...|      [hsbc]|          [1]|        www.scmp.com|      news_article|\n",
      "| 0.02918154001235962|{108441, applicat...|      1872|\\n\\n\\nOn one side...|http://online.wsj...|on one side are t...|[on, one, side, a...|[nationwide]|          [1]|      online.wsj.com|      news_article|\n",
      "|0.022928059101104736|{188983, applicat...|       629|Does the GOP Need...|http://www.bet.co...|does the gop need...|[does, the, gop, ...|[nationwide]|          [1]|         www.bet.com|      news_article|\n",
      "| 0.10605061054229736|{111138, applicat...|       475|I was cheated out...|http://www.thegua...|i was cheated out...|[i, was, cheated,...|  [barclays]|          [8]| www.theguardian.com|      news_article|\n",
      "+--------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+------------+-------------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02f787e-bf6f-418e-b2cc-fa2944f81a44",
   "metadata": {},
   "source": [
    "### Temporal columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1e109a0-8031-46bd-9f62-1fd981fb1c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"date\", to_date(col(\"metadata.WARC-Date\")))\n",
    "df = df.withColumn(\"day\", dayofmonth(col(\"date\")))\n",
    "df = df.withColumn(\"month\", month(col(\"date\")))\n",
    "df = df.withColumn(\"year\", year(col(\"date\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88fbd2f-0c33-44ee-92e6-1c285dcce9b1",
   "metadata": {},
   "source": [
    "### Drop Irrelevant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f548a426-b1db-474e-8d12-39985e15bbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"user_gen_prob\", \"metadata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab61e44-9a38-4c42-9578-61148f0f1cdf",
   "metadata": {},
   "source": [
    "### Summary of Final Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2201b9-0c3c-48de-8534-299eac595447",
   "metadata": {},
   "source": [
    "| Column Name         | Data Type          | Description                                      |\n",
    "|---------------------|--------------------|--------------------------------------------------|\n",
    "| `brand_name`        | Array of String    | List of UK bank brands mentioned in the text (e.g., [\"barclays\", \"nationwide\"]) |\n",
    "| `mention_count`     | Array of Integer   | Number of mentions for each brand in `brand_name` (e.g., [2, 1]) |\n",
    "| `content_type`      | String             | Classification of content (e.g., social_media, news_article, customer_review) |\n",
    "| `raw_text`          | String             | Original, unprocessed text from the dataset       |\n",
    "| `clean_text`        | String             | Preprocessed text for analysis (lowercase, no punctuation) |\n",
    "| `tokens`            | Array of String    | Tokenized words from `clean_text` for further processing |\n",
    "| `url`               | String             | Original URL of the content source               |\n",
    "| `url_domain`        | String             | Root domain extracted from `url` (e.g., x.com)   |\n",
    "| `word_count`        | Long               | Number of words in the content                   |\n",
    "| `date`              | Date               | Full crawl timestamp (e.g., 2024-11-24)          |\n",
    "| `day`               | Integer            | Day of the month from metadata        |\n",
    "| `month`             | Integer            | Month from crawl metadata                   |\n",
    "| `year`              | Integer            | Year from crawl metadata                    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ac84abe-c6e2-4bdb-bfbd-08dbc313ccd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- brand_name: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- mention_count: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      " |-- content_type: string (nullable = true)\n",
      " |-- raw_text: string (nullable = true)\n",
      " |-- clean_text: string (nullable = true)\n",
      " |-- tokens: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- url_domain: string (nullable = true)\n",
      " |-- word_count: long (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.selectExpr(\n",
    "    \"brand_name\",\n",
    "    \"mention_count\",\n",
    "    \"content_type\",\n",
    "    \"text AS raw_text\",\n",
    "    \"clean_text\",\n",
    "    \"tokens\",\n",
    "    \"url\",\n",
    "    \"url_domain\",\n",
    "    \"word_count\",\n",
    "    \"date\",\n",
    "    \"day\",\n",
    "    \"month\",\n",
    "    \"year\",\n",
    ")\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d7f73ee-3936-44db-9ca3-ccc040a18ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+----------+---+-----+----+\n",
      "|  brand_name|mention_count|      content_type|            raw_text|          clean_text|              tokens|                 url|          url_domain|word_count|      date|day|month|year|\n",
      "+------------+-------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+----------+---+-----+----+\n",
      "|[nationwide]|          [1]|      news_article|Forgot your passw...|forgot your passw...|[forgot, your, pa...|http://slashdot.o...|        slashdot.org|      6572|2014-07-14| 14|    7|2014|\n",
      "|      [hsbc]|          [1]|      news_article|Golf Digest edito...|golf digest edito...|[golf, digest, ed...|http://www.golfdi...|  www.golfdigest.com|       929|2014-07-14| 14|    7|2014|\n",
      "|      [hsbc]|          [1]|      news_article|Friday, June 18, ...|friday june write...|[friday, june, wr...|http://hotinterne...|hotinternet.blogs...|      5279|2014-07-14| 14|    7|2014|\n",
      "|[nationwide]|          [1]|      news_article|Get the Feds Out ...|get the feds out ...|[get, the, feds, ...|http://www.nation...|www.nationalrevie...|       910|2014-07-14| 14|    7|2014|\n",
      "|[nationwide]|          [1]|      news_article|1953 Pennsylvania...|pennsylvania rail...|[pennsylvania, ra...|http://en.wikiped...|    en.wikipedia.org|      1479|2014-07-14| 14|    7|2014|\n",
      "|[nationwide]|          [1]|     miscellaneous|OpinionTop of the...|opiniontop of the...|[opiniontop, of, ...|http://www.latime...|     www.latimes.com|       666|2014-07-14| 14|    7|2014|\n",
      "|[nationwide]|          [1]|      news_article|Call for Book Rev...|call for book rev...|[call, for, book,...|http://www.popmat...|  www.popmatters.com|      2931|2014-07-14| 14|    7|2014|\n",
      "|[nationwide]|          [1]|faq_knowledge_base|The Skeptics\\n\\nO...|the skeptics of m...|[the, skeptics, o...|http://nationalin...|nationalinterest.org|       523|2014-07-13| 13|    7|2014|\n",
      "|[nationwide]|          [1]|         blog_post|Zille links up wi...|zille links up wi...|[zille, links, up...|http://www.econom...|   www.economist.com|       458|2014-07-13| 13|    7|2014|\n",
      "|[nationwide]|          [1]|      news_article|Kurt Busch hoping...|kurt busch hoping...|[kurt, busch, hop...|http://www.utsand...|  www.utsandiego.com|       533|2014-07-14| 14|    7|2014|\n",
      "|[nationwide]|          [1]|     miscellaneous|LaHood calls for ...|lahood calls for ...|[lahood, calls, f...|http://www.wbez.o...|        www.wbez.org|       213|2014-07-13| 13|    7|2014|\n",
      "|[nationwide]|          [1]|      news_article|Credit Crunch | T...|credit crunch the...|[credit, crunch, ...|http://www.thenat...|   www.thenation.com|       959|2014-07-14| 14|    7|2014|\n",
      "|  [barclays]|          [1]|   customer_review|YOU ARE HERE: LAT...|you are here lat ...|[you, are, here, ...|http://articles.l...|articles.latimes.com|       836|2014-07-14| 14|    7|2014|\n",
      "|       [tsb]|          [1]|    user_generated|Howdy, Stranger!\\...|howdy stranger ho...|[howdy, stranger,...|http://forums.edm...|  forums.edmunds.com|       399|2014-07-14| 14|    7|2014|\n",
      "|  [barclays]|          [1]|      news_article|The only thing an...|the only thing an...|[the, only, thing...|http://online.wsj...|      online.wsj.com|       319|2014-07-14| 14|    7|2014|\n",
      "|  [starling]|          [2]|   customer_review|Forgot your passw...|forgot your passw...|[forgot, your, pa...|http://slashdot.o...|        slashdot.org|      1655|2014-07-14| 14|    7|2014|\n",
      "|      [hsbc]|          [1]|      news_article|A brief history o...|a brief history o...|[a, brief, histor...|http://www.scmp.c...|        www.scmp.com|      1727|2014-07-14| 14|    7|2014|\n",
      "|[nationwide]|          [1]|      news_article|\\n\\n\\nOn one side...|on one side are t...|[on, one, side, a...|http://online.wsj...|      online.wsj.com|      1872|2014-07-14| 14|    7|2014|\n",
      "|[nationwide]|          [1]|      news_article|Does the GOP Need...|does the gop need...|[does, the, gop, ...|http://www.bet.co...|         www.bet.com|       629|2014-07-14| 14|    7|2014|\n",
      "|  [barclays]|          [8]|      news_article|I was cheated out...|i was cheated out...|[i, was, cheated,...|http://www.thegua...| www.theguardian.com|       475|2014-07-14| 14|    7|2014|\n",
      "+------------+-------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+----------+---+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10282244-9c6a-429c-b667-0283e329b34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:================================>                       (14 + 1) / 24]"
     ]
    }
   ],
   "source": [
    "# num_rows = df.count()\n",
    "# num_cols = len(df.columns)\n",
    "# print(f\"Number of rows: {num_rows}\")\n",
    "# print(f\"Number of columns: {num_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2073e99-1894-41c8-8049-df3d9423f525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[brand_name: array<string>, mention_count: array<int>, content_type: string, raw_text: string, clean_text: string, tokens: array<string>, url: string, url_domain: string, word_count: bigint, date: date, day: int, month: int, year: int]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361545ab-175d-4f82-83f4-6b96a4e415ea",
   "metadata": {},
   "source": [
    "# 4. Brand Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc797f4e-2979-456e-a957-9ece9bead94d",
   "metadata": {},
   "source": [
    "In this section, sentiment analysis is performed on UK bank brand mentions using a hybrid approach combining lexicon-based (VADER) and a transformer-based model (FinBERT)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddc612b-d46d-4533-ad51-98fd21e17a1d",
   "metadata": {},
   "source": [
    "### 4.1 Lexicon-Based (VADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66693a6c-a05e-4cb8-bf68-a1df14046f1e",
   "metadata": {},
   "source": [
    "The following code performs brand sentiment analysis using NLTK's VADER (Valence Aware Dictionary and sEntiment Reasoner), a lexicon-based tool specifically designed for detecting sentiment in user-generated texts.\n",
    "\n",
    "VADER calculates 4 sentiment metrics for each text input:\n",
    "- `vader_score` (compound score): A normalized weighted composite score ranging from -1 (negative) to +1 (positive). Derived from the sum of valence scores of individual words, adjusted for modifiers (e.g., \"very good\" amplifies positivity).\n",
    "- `positive_score`, `neutral_score`, `negative_score`: Proportional metrics representing the text's positive, neutral, and negative sentiment (each ranges 0â€“1). The 3 scores sum to 1.\n",
    "\n",
    "`sentiment_label` is assigned based on the compound `vader_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd2c849d-24bf-419f-b5ca-f52aa83f6329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise VADER\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Calculates VADER sentiment\n",
    "def vader_sentiment(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return {\"compound\": 0.0, \"positive\": 0.0, \"neutral\": 0.0, \"negative\": 0.0}\n",
    "    scores = sid.polarity_scores(text)\n",
    "    return scores\n",
    "\n",
    "# Schema for VADER output\n",
    "vader_schema = StructType([\n",
    "    StructField(\"compound\", FloatType(), nullable=True),\n",
    "    StructField(\"pos\", FloatType(), nullable=True),\n",
    "    StructField(\"neu\", FloatType(), nullable=True),\n",
    "    StructField(\"neg\", FloatType(), nullable=True)\n",
    "])\n",
    "\n",
    "vader_udf = udf(vader_sentiment, vader_schema)\n",
    "df = df.withColumn(\"vader_sentiment\", vader_udf(col(\"clean_text\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cad9ef-fa39-4cbf-9fd3-8113e4ded011",
   "metadata": {},
   "source": [
    "### Sentiment Scores and Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7ae339e-8252-43e9-8e5f-8e5991cc193d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VADER Sentiment Scores and Labels:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.               (17 + 1) / 24]\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/socket.py\", line 720, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "25/06/06 00:33:19 ERROR Executor: Exception in task 17.0 in stage 16.0 (TID 96): Python worker exited unexpectedly (crashed)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 18\u001b[0m\n\u001b[1;32m     12\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvader_sentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mVADER Sentiment Scores and Labels:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbrand_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmention_count\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclean_text\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl_domain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvader_score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpositive_score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mneutral_score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnegative_score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msentiment_label\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m---> 18\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pyspark/sql/dataframe.py:972\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    964\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m    965\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    966\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    969\u001b[0m         },\n\u001b[1;32m    970\u001b[0m     )\n\u001b[0;32m--> 972\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mint_truncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"vader_score\", col(\"vader_sentiment.compound\"))\n",
    "df = df.withColumn(\"positive_score\", col(\"vader_sentiment.pos\"))\n",
    "df = df.withColumn(\"neutral_score\", col(\"vader_sentiment.neu\"))\n",
    "df = df.withColumn(\"negative_score\", col(\"vader_sentiment.neg\"))\n",
    "\n",
    "# Sentiment Label\n",
    "df = df.withColumn(\"sentiment_label\",\n",
    "    when(col(\"vader_score\") > 0.05, \"Positive\")\n",
    "    .when(col(\"vader_score\") < -0.05, \"Negative\")\n",
    "    .otherwise(\"Neutral\"))\n",
    "\n",
    "df = df.drop(\"vader_sentiment\")\n",
    "\n",
    "print(\"\\nVADER Sentiment Scores and Labels:\")\n",
    "df.select(\n",
    "    \"brand_name\", \"mention_count\", \"content_type\", \"clean_text\", \"url_domain\", \"vader_score\", \"positive_score\",\n",
    "    \"neutral_score\", \"negative_score\", \"sentiment_label\"\n",
    ").show(10, truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7562f17-23e8-4cc6-aa44-0897c3c5195d",
   "metadata": {},
   "source": [
    "### Overall Sentiment Aggregation: *avg_vader_score*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3457c5-852e-453e-b311-d970f13a236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associates sentiment with each brand\n",
    "df_exploded = df.select(\n",
    "    explode(col(\"brand_name\")).alias(\"brand\"),\n",
    "    col(\"vader_score\"),\n",
    "    col(\"content_type\"),\n",
    "    col(\"year\"),\n",
    "    col(\"month\"),\n",
    "    col(\"day\")\n",
    ")\n",
    "\n",
    "# Sentiment by brand and content_type\n",
    "sentiment_summary = df_exploded.groupBy(\"brand\", \"content_type\").agg(\n",
    "    avg(\"vader_score\").alias(\"avg_vader_score\")\n",
    ").orderBy(\"brand\", \"content_type\")\n",
    "\n",
    "# Sentiment label\n",
    "sentiment_summary = sentiment_summary.withColumn(\n",
    "    \"avg_sentiment_label\",\n",
    "    when(col(\"avg_vader_score\") > 0.05, \"Positive\")\n",
    "    .when(col(\"avg_vader_score\") < -0.05, \"Negative\")\n",
    "    .otherwise(\"Neutral\")\n",
    ")\n",
    "\n",
    "print(\"VADER Sentiment Summary by Brand and Content Type:\")\n",
    "sentiment_summary.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476f54a9-a9d0-4f70-9ce3-48909f170f43",
   "metadata": {},
   "source": [
    "### 4.2 Transformer-Based\n",
    "**FinBERT** model is implemented for brand sentiment analysis of UK financial services brands due to its:\n",
    "- Domain-specialisation:  Explicitly trained on financial texts (10M+ finance docs), including financial news, analyst reports, earnings call transcripts, SEC/FCA filings, and other regulatory documents. It has good understanding of key financial concepts, such as, financial metrics, market movements, and regulatory language.\n",
    "- Sentiment granularity: 3-class (positive/neutral/negative)\n",
    "- Numerical sensitivity: Handles earnings and percentages well.\n",
    "  \n",
    "The following outputs are computed:\n",
    "- `finbert_label` â€“ the sentiment class with the highest average probability across all chunks\n",
    "- `finbert_score` â€“ the sentiment polarity score, calculated as Positive - Negative probability.\n",
    "- `finbert_confidence`: How confident FinBERT is about its prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6863e15-59d1-41de-8028-0c80247b4906",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# FinBERT tokenizer and model\n",
    "finbert_tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\", use_fast=True)\n",
    "finbert_model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\").to(device)\n",
    "finbert_pipeline = pipeline(\n",
    "    task=\"sentiment-analysis\",\n",
    "    model=finbert_model,\n",
    "    tokenizer=finbert_tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1,\n",
    "    torch_dtype=torch.float16,\n",
    "    return_all_scores=True,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=512,\n",
    "    batch_size=32\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0deaf6-c496-44b2-93d0-e43e97fd9f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_chunks(text, tokenizer):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return [\"\"]\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), 510):  # 510 to allow for special tokens\n",
    "        chunk_tokens = tokens[i:i + 510]\n",
    "        chunk_text = tokenizer.convert_tokens_to_string(chunk_tokens)\n",
    "        chunks.append(chunk_text)\n",
    "    return chunks if chunks else [\"\"]\n",
    "    \n",
    "def analyze_finbert(text):\n",
    "    try:\n",
    "        chunks = prepare_chunks(text, finbert_tokenizer)\n",
    "        if not chunks or all(not c.strip() for c in chunks):\n",
    "            return \"neutral\", 0.0, 0.0, {\"positive\": 0.0, \"neutral\": 1.0, \"negative\": 0.0}\n",
    "\n",
    "        results = finbert_pipeline(chunks)\n",
    "        cumulative_scores = {\"positive\": 0.0, \"neutral\": 0.0, \"negative\": 0.0}\n",
    "        confidences = []\n",
    "        count = 0\n",
    "\n",
    "        for r in results:\n",
    "            if isinstance(r, list):\n",
    "                for entry in r:\n",
    "                    label = entry[\"label\"].lower()\n",
    "                    score = entry[\"score\"]\n",
    "                    cumulative_scores[label] += score\n",
    "                confidences.append(max(entry[\"score\"] for entry in r))\n",
    "                count += 1\n",
    "\n",
    "        if count == 0:\n",
    "            return \"neutral\", 0.0, 0.0, {\"positive\": 0.0, \"neutral\": 1.0, \"negative\": 0.0}\n",
    "\n",
    "        # Normalise all scores\n",
    "        avg_scores = {k: v / count for k, v in cumulative_scores.items()}\n",
    "        avg_confidence = sum(confidences) / count\n",
    "\n",
    "        # Polarity score\n",
    "        polarity = avg_scores[\"positive\"] - avg_scores[\"negative\"]\n",
    "\n",
    "        # Final predicted label\n",
    "        if abs(polarity) < 0.15:\n",
    "            final_label = \"neutral\"\n",
    "        else:\n",
    "            final_label = \"positive\" if polarity > 0 else \"negative\"\n",
    "\n",
    "        return (\n",
    "            final_label,\n",
    "            round(polarity, 4),\n",
    "            round(avg_confidence, 4),\n",
    "            {k: round(v, 4) for k, v in avg_scores.items()}\n",
    "        )\n",
    "\n",
    "    except torch.cuda.OutOfMemoryError:\n",
    "        torch.cuda.empty_cache()\n",
    "        return analyze_finbert_vader_style(text)\n",
    "    except Exception as e:\n",
    "        print(f\"FinBERT error on text {text[:50]}...: {str(e)}\")\n",
    "        return \"neutral\", 0.0, 0.0, {\"positive\": 0.0, \"neutral\": 1.0, \"negative\": 0.0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7dfe27-a1a2-42b5-8049-78561aab2a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and truncate text\n",
    "df = df.filter(col(\"clean_text\").isNotNull() & col(\"clean_text\").cast(\"string\").isNotNull())\n",
    "df = df.withColumn(\"clean_text\", substring(col(\"clean_text\"), 1, 512))\n",
    "df.cache()\n",
    "\n",
    "# Row index for joining\n",
    "df = df.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "\n",
    "# Convert to Pandas for transformer processing\n",
    "pandas_df = df.select(\"row_id\", \"clean_text\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157d0994-d7cc-448d-8983-803e16458234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute analysis\n",
    "finbert_results = [analyze_finbert(text) for text in pandas_df[\"clean_text\"]]\n",
    "\n",
    "# Sentiment label, score and confidence\n",
    "pandas_df[\"finbert_label\"] = [r[0] for r in finbert_results]\n",
    "pandas_df[\"finbert_score\"] = [r[1] for r in finbert_results]\n",
    "pandas_df[\"finbert_confidence\"] = [r[2] for r in finbert_results]\n",
    "\n",
    "# Individual sentiment scores\n",
    "pandas_df[\"finbert_dist_positive\"] = [r[3][\"positive\"] for r in finbert_results]\n",
    "pandas_df[\"finbert_dist_neutral\"] = [r[3][\"neutral\"] for r in finbert_results]\n",
    "pandas_df[\"finbert_dist_negative\"] = [r[3][\"negative\"] for r in finbert_results]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03afd9b-6a24-42d2-af00-080bb2422fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "finbert_csv = \"data/finbert_results.csv\"\n",
    "pandas_df[[\n",
    "    \"row_id\", \"finbert_label\", \"finbert_score\", \"finbert_confidence\",\n",
    "    \"finbert_dist_positive\", \"finbert_dist_neutral\", \"finbert_dist_negative\"\n",
    "]].to_csv(finbert_csv, index=False)\n",
    "\n",
    "# Transform back to Spark\n",
    "transformer_df = spark.read.csv(finbert_csv, header=True, inferSchema=True)\n",
    "df = df.join(transformer_df, \"row_id\").drop(\"row_id\")\n",
    "\n",
    "print(\"\\nDisplaying DataFrame after transformer processing:\")\n",
    "df.select(\n",
    "    \"brand_name\", \"mention_count\", \"content_type\", \"clean_text\", \"vader_score\", \"sentiment_label\",\n",
    "    \"finbert_label\", \"finbert_score\", \"finbert_confidence\"\n",
    ").show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa12fe9f-5d83-4110-8e25-10d51f26f89a",
   "metadata": {},
   "source": [
    "## 4.3 Hybrid Sentiment Analysis\n",
    "The following section combines VADER and FinBERT predictions, weighted by `content_type`. VADER is up-weighted for `user_generated` and `customer_review`, and FinBERT for `news_article` and `regulatory_document`. This outputs `hybrid_sentiment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7bdb59e2-c8c4-451a-a1d1-8be9e6ffa39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(StringType())\n",
    "def hybrid_sentiment(vader_score, finbert_score, content_type):\n",
    "    if vader_score is None or finbert_score is None:\n",
    "        return \"Neutral\"\n",
    "    \n",
    "    # Adjusted weights (sum to 1)\n",
    "    if content_type in [\"user_generated\", \"customer_review\", \"forum_post\"]:\n",
    "        weights = {\"vader\": 0.6, \"finbert\": 0.4}\n",
    "    elif content_type in [\"news_article\", \"regulatory_document\"]:\n",
    "        weights = {\"vader\": 0.3, \"finbert\": 0.7}\n",
    "    else:\n",
    "        weights = {\"vader\": 0.5, \"finbert\": 0.5}\n",
    "    \n",
    "    combined_score = (\n",
    "        weights[\"vader\"] * vader_score +\n",
    "        weights[\"finbert\"] * finbert_score\n",
    "    )\n",
    "    \n",
    "    if combined_score > 0.05:\n",
    "        return \"Positive\"\n",
    "    elif combined_score < -0.05:\n",
    "        return \"Negative\"\n",
    "    return \"Neutral\"\n",
    "\n",
    "df = df.withColumn(\"hybrid_sentiment\", hybrid_sentiment(\n",
    "    col(\"vader_score\"),\n",
    "    col(\"finbert_score\"),\n",
    "    col(\"content_type\")\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b5ffa6e3-432b-4713-abff-9d85e8157c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+------------------+--------------------------------------------------+----------------+--------------+-------------+\n",
      "|  brand_name|mention_count|      content_type|                                        clean_text|hybrid_sentiment|compound_score|finbert_score|\n",
      "+------------+-------------+------------------+--------------------------------------------------+----------------+--------------+-------------+\n",
      "|[nationwide]|          [1]|         blog_post|follow slashdot blog updates by subscribing to ...|        Positive|        0.9943|      -0.1004|\n",
      "|       [tsb]|          [2]|    user_generated|gm ceo mary barra congressional hearings on rec...|        Negative|       -0.9969|      -0.1355|\n",
      "|  [barclays]|          [4]|   customer_review|the common good former barclays ceo feels respo...|        Positive|        0.9588|      -0.7265|\n",
      "|  [starling]|          [1]|      news_article|get connected facebook twitter sign in classifi...|        Negative|       -0.9876|      -0.0539|\n",
      "|[nationwide]|          [1]|      news_article|dont pin your hopes on the party of lincoln rep...|        Positive|        0.9885|      -0.0384|\n",
      "|[nationwide]|          [1]|      news_article|fri dec updated am letters to the editor decemb...|        Positive|       -0.9182|       0.8481|\n",
      "|[nationwide]|          [2]|    user_generated|australia forum whats a nice girl like you doin...|        Positive|        0.9999|       0.0177|\n",
      "|[nationwide]|          [1]|         blog_post|federal judge says healthcare law is unconstitu...|         Neutral|        0.4692|      -0.4807|\n",
      "|[nationwide]|          [1]|      news_article|return to transcripts main page more details to...|        Positive|        0.9989|       -0.052|\n",
      "|[nationwide]|          [1]|faq_knowledge_base|senate okays drilling in the gulf of mexico or ...|        Negative|       -0.4588|       0.2107|\n",
      "+------------+-------------+------------------+--------------------------------------------------+----------------+--------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "    \"brand_name\", \"mention_count\", \"content_type\", \"clean_text\", \"hybrid_sentiment\", \"vader_score\", \"finbert_score\"\n",
    ").show(10, truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea05365-b1ef-4efc-b0be-4574d64dcb3a",
   "metadata": {},
   "source": [
    "## 4.4 Brand-Specific Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ac738a5b-99f0-4ba9-a410-2f8c79bd0d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_sentiment_df = df.select(\n",
    "    explode(arrays_zip(col(\"brand_name\"), col(\"mention_count\"))).alias(\"exploded\"),\n",
    "    col(\"content_type\"),\n",
    "    col(\"vader_score\"),\n",
    "    col(\"sentiment_label\"),\n",
    "    col(\"finbert_label\"),\n",
    "    col(\"finbert_score\"),\n",
    "    col(\"finbert_confidence\"),\n",
    "    col(\"hybrid_sentiment\"),\n",
    "    col(\"date\"),\n",
    "    col(\"month\"),\n",
    "    col(\"year\")\n",
    ").select(\n",
    "    col(\"exploded.brand_name\").alias(\"brand\"),\n",
    "    col(\"exploded.mention_count\").alias(\"mentions\"),\n",
    "    col(\"content_type\"),\n",
    "    col(\"vader_score\"),\n",
    "    col(\"sentiment_label\"),\n",
    "    col(\"finbert_label\"),\n",
    "    col(\"finbert_score\"),\n",
    "    col(\"finbert_confidence\"),\n",
    "    col(\"hybrid_sentiment\"),\n",
    "    col(\"date\"),\n",
    "    col(\"month\"),\n",
    "    col(\"year\")\n",
    ")\n",
    "\n",
    "# Filter for Lloyds and Barclays\n",
    "brands_of_interest = [\"lloyds\", \"barclays\"]\n",
    "brand_specific_df = brand_sentiment_df.filter(col(\"brand\").isin(brands_of_interest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f404ad95-8978-4e85-a74a-bfa872b8a406",
   "metadata": {},
   "source": [
    "### Sentiment by brand and content type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5c3e8759-5bc1-4242-8cc5-033fa3aea6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Brand Sentiment Summary (Lloyds and Barclays):\n",
      "+--------+-------------------+----------------+--------------+\n",
      "|brand   |content_type       |hybrid_sentiment|total_mentions|\n",
      "+--------+-------------------+----------------+--------------+\n",
      "|barclays|advertising_content|Positive        |1             |\n",
      "|barclays|blog_post          |Positive        |3             |\n",
      "|barclays|customer_review    |Negative        |4             |\n",
      "|barclays|customer_review    |Positive        |9             |\n",
      "|barclays|faq_knowledge_base |Positive        |2             |\n",
      "|barclays|news_article       |Neutral         |4             |\n",
      "|barclays|news_article       |Positive        |22            |\n",
      "|barclays|news_article       |Negative        |12            |\n",
      "|barclays|other              |Negative        |1             |\n",
      "|barclays|other              |Positive        |1             |\n",
      "|lloyds  |customer_review    |Negative        |16            |\n",
      "|lloyds  |customer_review    |Positive        |3             |\n",
      "|lloyds  |news_article       |Negative        |25            |\n",
      "|lloyds  |news_article       |Neutral         |3             |\n",
      "|lloyds  |news_article       |Positive        |13            |\n",
      "|lloyds  |other              |Negative        |5             |\n",
      "|lloyds  |user_generated     |Positive        |1             |\n",
      "+--------+-------------------+----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "brand_summary = brand_specific_df.groupBy(\n",
    "    \"brand\", \"content_type\", \"hybrid_sentiment\"\n",
    ").agg({\"mentions\": \"sum\"}).withColumnRenamed(\"sum(mentions)\", \"total_mentions\")\n",
    "\n",
    "print(\"\\nBrand Sentiment Summary (Lloyds and Barclays):\")\n",
    "brand_summary.orderBy(\"brand\", \"content_type\").show(50, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f46caa-f3b9-4d8b-8c0c-37957cc16349",
   "metadata": {},
   "source": [
    "## 4.5 Visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcbda1c-b7e0-4f5d-98bd-8568e7d17e2a",
   "metadata": {},
   "source": [
    "### Sentiment distribution by brand and content type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d895be79-23a5-4df1-9037-0ddeb2a378de",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_sentiment_counts = brand_summary.groupBy(\"brand\", \"hybrid_sentiment\").agg({\"total_mentions\": \"sum\"}).collect()\n",
    "brands = sorted(set(row[\"brand\"] for row in brand_sentiment_counts))\n",
    "sentiments = [\"Positive\", \"Neutral\", \"Negative\"]\n",
    "data = {sentiment: [0] * len(brands) for sentiment in sentiments}\n",
    "for row in brand_sentiment_counts:\n",
    "    brand_idx = brands.index(row[\"brand\"])\n",
    "    sentiment = row[\"hybrid_sentiment\"]\n",
    "    data[sentiment][brand_idx] = row[\"sum(total_mentions)\"]\n",
    "\n",
    "bar_chart_data = {\n",
    "    \"positive\": data[\"Positive\"],\n",
    "    \"neutral\": data[\"Neutral\"],\n",
    "    \"negative\": data[\"Negative\"],\n",
    "    \"labels\": [\"Barclays\", \"Lloyds\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0df466d5-84f1-4334-a49d-74d801f9ade8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script src=\"https://cdn.jsdelivr.net/npm/chart.js\"></script>\n",
       "<div>\n",
       "    <canvas id=\"barChart\" width=\"600\" height=\"300\"></canvas>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "var barChartData = {\n",
       "    labels: ['Barclays', 'Lloyds'],\n",
       "    datasets: [\n",
       "        {\n",
       "            label: 'Positive',\n",
       "            data: [38, 17],\n",
       "            backgroundColor: 'rgba(75, 192, 192, 0.6)',\n",
       "            borderColor: 'rgba(75, 192, 192, 1)',\n",
       "            borderWidth: 1\n",
       "        },\n",
       "        {\n",
       "            label: 'Neutral',\n",
       "            data: [4, 3],\n",
       "            backgroundColor: 'rgba(153, 162, 235, 0.6)',\n",
       "            borderColor: 'rgba(153, 162, 235, 1)',\n",
       "            borderWidth: 1\n",
       "        },\n",
       "        {\n",
       "            label: 'Negative',\n",
       "            data: [17, 46],\n",
       "            backgroundColor: 'rgba(255, 99, 132, 0.6)',\n",
       "            borderColor: 'rgba(255, 99, 132, 1)',\n",
       "            borderWidth: 1\n",
       "        }\n",
       "    ]\n",
       "};\n",
       "\n",
       "var barCtx = document.getElementById('barChart').getContext('2d');\n",
       "new Chart(barCtx, {\n",
       "    type: 'bar',\n",
       "    data: barChartData,\n",
       "    options: {\n",
       "        scales: {\n",
       "            x: { title: { display: true, text: 'Brand' } },\n",
       "            y: { title: { display: true, text: 'Total Mentions' }, beginAtZero: true }\n",
       "        },\n",
       "        plugins: {\n",
       "            title: { display: true, text: 'Hybrid Sentiment Distribution for Lloyds and Barclays' },\n",
       "            legend: { display: true, position: 'top' }\n",
       "        }\n",
       "    }\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, Javascript\n",
    "\n",
    "html_setup = \"\"\"\n",
    "<script src=\"https://cdn.jsdelivr.net/npm/chart.js\"></script>\n",
    "<div>\n",
    "    <canvas id=\"barChart\" width=\"600\" height=\"300\"></canvas>\n",
    "</div>\n",
    "\"\"\"\n",
    "display(HTML(html_setup))\n",
    "\n",
    "# Pass data to JavaScript\n",
    "bar_chart_js_data = f\"\"\"\n",
    "var barChartData = {{\n",
    "    labels: {bar_chart_data['labels']},\n",
    "    datasets: [\n",
    "        {{\n",
    "            label: 'Positive',\n",
    "            data: {bar_chart_data['positive']},\n",
    "            backgroundColor: 'rgba(75, 192, 192, 0.6)',\n",
    "            borderColor: 'rgba(75, 192, 192, 1)',\n",
    "            borderWidth: 1\n",
    "        }},\n",
    "        {{\n",
    "            label: 'Neutral',\n",
    "            data: {bar_chart_data['neutral']},\n",
    "            backgroundColor: 'rgba(153, 162, 235, 0.6)',\n",
    "            borderColor: 'rgba(153, 162, 235, 1)',\n",
    "            borderWidth: 1\n",
    "        }},\n",
    "        {{\n",
    "            label: 'Negative',\n",
    "            data: {bar_chart_data['negative']},\n",
    "            backgroundColor: 'rgba(255, 99, 132, 0.6)',\n",
    "            borderColor: 'rgba(255, 99, 132, 1)',\n",
    "            borderWidth: 1\n",
    "        }}\n",
    "    ]\n",
    "}};\n",
    "\"\"\"\n",
    "\n",
    "render_bar_chart_js = \"\"\"\n",
    "var barCtx = document.getElementById('barChart').getContext('2d');\n",
    "new Chart(barCtx, {\n",
    "    type: 'bar',\n",
    "    data: barChartData,\n",
    "    options: {\n",
    "        scales: {\n",
    "            x: { title: { display: true, text: 'Brand' } },\n",
    "            y: { title: { display: true, text: 'Total Mentions' }, beginAtZero: true }\n",
    "        },\n",
    "        plugins: {\n",
    "            title: { display: true, text: 'Hybrid Sentiment Distribution for Lloyds and Barclays' },\n",
    "            legend: { display: true, position: 'top' }\n",
    "        }\n",
    "    }\n",
    "});\n",
    "\"\"\"\n",
    "\n",
    "display(Javascript(bar_chart_js_data + render_bar_chart_js))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3676ed-be0c-40bc-a3f9-f440823d71af",
   "metadata": {},
   "source": [
    "### Temporal sentiment trends for Lloyds and Barclays (Negative sentiment over time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "64c5cb99-8951-4e06-aec6-57f465680f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 70:=============================>                            (1 + 1) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line Chart Data: {'time_labels': ['2014-03', '2014-07', '2014-12'], 'lloyds_data': [3, 16, 27], 'barclays_data': [3, 4, 10]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "temporal_data = temporal_summary.filter(col(\"hybrid_sentiment\") == \"Negative\").groupBy(\"brand\", \"year\", \"month\").agg({\"total_mentions\": \"sum\"}).collect()\n",
    "\n",
    "time_labels = sorted(set(f\"{row['year']}-{row['month']:02d}\" for row in temporal_data))\n",
    "lloyds_data = [0] * len(time_labels)\n",
    "barclays_data = [0] * len(time_labels)\n",
    "for row in temporal_data:\n",
    "    time_idx = time_labels.index(f\"{row['year']}-{row['month']:02d}\")\n",
    "    if row['brand'] == \"lloyds\":\n",
    "        lloyds_data[time_idx] = row[\"sum(total_mentions)\"]\n",
    "    elif row['brand'] == \"barclays\":\n",
    "        barclays_data[time_idx] = row[\"sum(total_mentions)\"]\n",
    "\n",
    "# Prepare line chart data\n",
    "line_chart_data = {\n",
    "    \"time_labels\": time_labels,\n",
    "    \"lloyds_data\": lloyds_data,\n",
    "    \"barclays_data\": barclays_data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d261514a-9d80-4b6e-b35f-44f942946e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script src=\"https://cdn.jsdelivr.net/npm/chart.js\"></script>\n",
       "<div>\n",
       "    <canvas id=\"lineChart\" width=\"600\" height=\"300\"></canvas>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "var lineChartData = {\n",
       "    labels: ['2014-03', '2014-07', '2014-12'],\n",
       "    datasets: [\n",
       "        {\n",
       "            label: 'Lloyds Positive Mentions',\n",
       "            data: [3, 16, 27],\n",
       "            borderColor: 'rgba(75, 192, 192, 1)',\n",
       "            backgroundColor: 'rgba(75, 192, 192, 0.2)',\n",
       "            fill: true,\n",
       "            tension: 0.4\n",
       "        },\n",
       "        {\n",
       "            label: 'Barclays Positive Mentions',\n",
       "            data: [3, 4, 10],\n",
       "            borderColor: 'rgba(255, 99, 132, 1)',\n",
       "            backgroundColor: 'rgba(255, 99, 132, 0.2)',\n",
       "            fill: true,\n",
       "            tension: 0.4\n",
       "        }\n",
       "    ]\n",
       "};\n",
       "\n",
       "var lineCtx = document.getElementById('lineChart').getContext('2d');\n",
       "new Chart(lineCtx, {\n",
       "    type: 'line',\n",
       "    data: lineChartData,\n",
       "    options: {\n",
       "        scales: {\n",
       "            x: { title: { display: true, text: 'Year-Month' } },\n",
       "            y: { title: { display: true, text: 'Positive Mentions' }, beginAtZero: true }\n",
       "        },\n",
       "        plugins: {\n",
       "            title: { display: true, text: 'Positive Sentiment Trends for Lloyds and Barclays' },\n",
       "            legend: { display: true, position: 'top' }\n",
       "        }\n",
       "    }\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Include Chart.js and create canvas element\n",
    "html_setup = \"\"\"\n",
    "<script src=\"https://cdn.jsdelivr.net/npm/chart.js\"></script>\n",
    "<div>\n",
    "    <canvas id=\"lineChart\" width=\"600\" height=\"300\"></canvas>\n",
    "</div>\n",
    "\"\"\"\n",
    "display(HTML(html_setup))\n",
    "\n",
    "# Pass line chart data to JavaScript\n",
    "line_chart_js_data = f\"\"\"\n",
    "var lineChartData = {{\n",
    "    labels: {line_chart_data['time_labels']},\n",
    "    datasets: [\n",
    "        {{\n",
    "            label: 'Lloyds Positive Mentions',\n",
    "            data: {line_chart_data['lloyds_data']},\n",
    "            borderColor: 'rgba(75, 192, 192, 1)',\n",
    "            backgroundColor: 'rgba(75, 192, 192, 0.2)',\n",
    "            fill: true,\n",
    "            tension: 0.4\n",
    "        }},\n",
    "        {{\n",
    "            label: 'Barclays Positive Mentions',\n",
    "            data: {line_chart_data['barclays_data']},\n",
    "            borderColor: 'rgba(255, 99, 132, 1)',\n",
    "            backgroundColor: 'rgba(255, 99, 132, 0.2)',\n",
    "            fill: true,\n",
    "            tension: 0.4\n",
    "        }}\n",
    "    ]\n",
    "}};\n",
    "\"\"\"\n",
    "\n",
    "# Render the line chart\n",
    "render_line_chart_js = \"\"\"\n",
    "var lineCtx = document.getElementById('lineChart').getContext('2d');\n",
    "new Chart(lineCtx, {\n",
    "    type: 'line',\n",
    "    data: lineChartData,\n",
    "    options: {\n",
    "        scales: {\n",
    "            x: { title: { display: true, text: 'Year-Month' } },\n",
    "            y: { title: { display: true, text: 'Positive Mentions' }, beginAtZero: true }\n",
    "        },\n",
    "        plugins: {\n",
    "            title: { display: true, text: 'Positive Sentiment Trends for Lloyds and Barclays' },\n",
    "            legend: { display: true, position: 'top' }\n",
    "        }\n",
    "    }\n",
    "});\n",
    "\"\"\"\n",
    "\n",
    "# Combine and display\n",
    "display(Javascript(line_chart_js_data + render_line_chart_js))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e042877c-015d-4c81-9b0f-6c15be08b4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
